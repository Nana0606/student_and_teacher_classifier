{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 功能简介\n",
    "\n",
    "本py文件主要用于特征选择方法的确定和特征选择参数的确定，具体如下：\n",
    "\n",
    "### 一、使用方差选择（Filter方法）\n",
    "\n",
    "1、特征选择\n",
    "\n",
    "2、使用网格搜索确定特征选择参数\n",
    "\n",
    "3、使用xgboost训练模型\n",
    "\n",
    "### 二、使用递归特征消除法（Wrapper方法）\n",
    "\n",
    "1、使用RFE和RFECV进行特征选择\n",
    "\n",
    "2、网格搜索确定保留特征数\n",
    "\n",
    "3、使用xgboost训练模型\n",
    "\n",
    "### 三、使用正则化（Embedded方法）\n",
    "\n",
    "1、使用L1正则化\n",
    "\n",
    "2、网格搜索确定正则项系数\n",
    "\n",
    "3、使用LinearSVC训练模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold, RFE, RFECV\n",
    "from sklearn.feature_extraction import DictVectorizer  \n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "import pickle\n",
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.Connect(\n",
    "    host=\"localhost\",\n",
    "    port=3306,\n",
    "    user=\"root\",\n",
    "    passwd=\"root\",\n",
    "    charset=\"utf8\",\n",
    "    db=\"project_researchers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train_data: (17844, 21)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17844 entries, 0 to 17843\n",
      "Data columns (total 21 columns):\n",
      "bys_cn                17608 non-null float64\n",
      "hindex_cn             17707 non-null float64\n",
      "a_paper               17844 non-null int64\n",
      "b_paper               17844 non-null int64\n",
      "c_paper               17844 non-null int64\n",
      "papernum2017          17844 non-null int64\n",
      "papernum2016          17844 non-null int64\n",
      "papernum2015          17844 non-null int64\n",
      "papernum2014          17844 non-null int64\n",
      "papernum2013          17844 non-null int64\n",
      "num_journal           17844 non-null int64\n",
      "num_conference        17844 non-null int64\n",
      "degree                17774 non-null float64\n",
      "pagerank              17774 non-null float64\n",
      "degree_centrality     17774 non-null float64\n",
      "diff_year             17774 non-null float64\n",
      "coauthors_top10000    17844 non-null int64\n",
      "coauthors_top20000    17844 non-null int64\n",
      "coauthors_top30000    17844 non-null int64\n",
      "category              17844 non-null int64\n",
      "label                 17844 non-null int64\n",
      "dtypes: float64(6), int64(15)\n",
      "memory usage: 2.9 MB\n",
      "train_data.info(): None\n"
     ]
    }
   ],
   "source": [
    "def get_train_data(connection):\n",
    "    \"\"\"\n",
    "    查询训练数据，包括特征和标签\n",
    "    :param connection:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    sql_select = \"\"\"\n",
    "     SELECT bys_cn, hindex_cn,a_conf+a_journal as a_paper, b_conf + b_journal as b_paper,c_conf + c_journal as c_paper,papernum2017, papernum2016, papernum2015, papernum2014, papernum2013,num_journal,num_conference, project_num, degree, pagerank,degree_centrality,last_year - first_year as diff_year , coauthors_top10000, coauthors_top20000, coauthors_top30000, category, label \n",
    "     FROM classifier_isTeacher_xgbc WHERE label = 1 and teac_id > 174 and category is not null\n",
    "     UNION ALL\n",
    "     SELECT bys_cn, hindex_cn,a_conf+a_journal as a_paper, b_conf + b_journal as b_paper,c_conf + c_journal as c_paper,papernum2017, papernum2016, papernum2015, papernum2014, papernum2013,num_journal,num_conference, project_num, degree, pagerank,degree_centrality,last_year - first_year as diff_year , coauthors_top10000, coauthors_top20000, coauthors_top30000, category, label \n",
    "     FROM classifier_isTeacher_xgbc WHERE label = 0 and teac_id > 64438 and category is not null\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(sql_select, connection)\n",
    "    all_features = ['bys_cn', 'hindex_cn', 'a_paper', 'b_paper', 'c_paper', 'papernum2017', 'papernum2016', 'papernum2015', 'papernum2014', 'papernum2013', 'num_journal', 'num_conference',  'degree', 'pagerank', 'degree_centrality', 'diff_year', 'coauthors_top10000', 'coauthors_top20000', 'coauthors_top30000', 'category', 'label']\n",
    "    data = df[all_features]\n",
    "    return data\n",
    "\n",
    "train_data = get_train_data(connection)\n",
    "print(\"shape of train_data:\", train_data.shape)\n",
    "print(\"train_data.info():\", train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of test_data: (850, 21)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 850 entries, 0 to 849\n",
      "Data columns (total 21 columns):\n",
      "bys_cn                834 non-null float64\n",
      "hindex_cn             850 non-null int64\n",
      "a_paper               850 non-null int64\n",
      "b_paper               850 non-null int64\n",
      "c_paper               850 non-null int64\n",
      "papernum2017          850 non-null int64\n",
      "papernum2016          850 non-null int64\n",
      "papernum2015          850 non-null int64\n",
      "papernum2014          850 non-null int64\n",
      "papernum2013          850 non-null int64\n",
      "num_journal           850 non-null int64\n",
      "num_conference        850 non-null int64\n",
      "degree                849 non-null float64\n",
      "pagerank              849 non-null float64\n",
      "degree_centrality     849 non-null float64\n",
      "diff_year             849 non-null float64\n",
      "coauthors_top10000    850 non-null int64\n",
      "coauthors_top20000    850 non-null int64\n",
      "coauthors_top30000    850 non-null int64\n",
      "category              850 non-null int64\n",
      "label                 850 non-null int64\n",
      "dtypes: float64(5), int64(16)\n",
      "memory usage: 139.5 KB\n",
      "test_data.info(): None\n"
     ]
    }
   ],
   "source": [
    "def get_test_data(connection):\n",
    "    \"\"\"\n",
    "    查询测试数据，包括特征和标签\n",
    "    :param connection:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    sql_select = \"\"\"\n",
    "     SELECT bys_cn, hindex_cn,a_conf+a_journal as a_paper, b_conf + b_journal as b_paper,c_conf + c_journal as c_paper,papernum2017, papernum2016, papernum2015, papernum2014, papernum2013,num_journal,num_conference, project_num, degree, pagerank,degree_centrality,last_year - first_year as diff_year , coauthors_top10000, coauthors_top20000, coauthors_top30000, category, label \n",
    "     FROM classifier_isTeacher_xgbc WHERE label = 1 and teac_id <= 174 and category is not null\n",
    "     UNION ALL\n",
    "     SELECT bys_cn, hindex_cn,a_conf+a_journal as a_paper, b_conf + b_journal as b_paper,c_conf + c_journal as c_paper,papernum2017, papernum2016, papernum2015, papernum2014, papernum2013,num_journal,num_conference, project_num, degree, pagerank,degree_centrality,last_year - first_year as diff_year , coauthors_top10000, coauthors_top20000, coauthors_top30000, category, label \n",
    "     FROM classifier_isTeacher_xgbc WHERE label = 0 and teac_id <= 64438 and category is not null\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(sql_select, connection)\n",
    "    all_features = ['bys_cn', 'hindex_cn', 'a_paper', 'b_paper', 'c_paper', 'papernum2017', 'papernum2016', 'papernum2015', 'papernum2014', 'papernum2013', 'num_journal', 'num_conference',  'degree', 'pagerank', 'degree_centrality', 'diff_year', 'coauthors_top10000', 'coauthors_top20000', 'coauthors_top30000', 'category', 'label']\n",
    "    data = df[all_features]\n",
    "    return data\n",
    "\n",
    "test_data = get_test_data(connection)\n",
    "print(\"shape of test_data:\", test_data.shape)\n",
    "print(\"test_data.info():\", test_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train_data:: (17539, 21)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17539 entries, 0 to 17843\n",
      "Data columns (total 21 columns):\n",
      "bys_cn                17539 non-null float64\n",
      "hindex_cn             17539 non-null float64\n",
      "a_paper               17539 non-null int64\n",
      "b_paper               17539 non-null int64\n",
      "c_paper               17539 non-null int64\n",
      "papernum2017          17539 non-null int64\n",
      "papernum2016          17539 non-null int64\n",
      "papernum2015          17539 non-null int64\n",
      "papernum2014          17539 non-null int64\n",
      "papernum2013          17539 non-null int64\n",
      "num_journal           17539 non-null int64\n",
      "num_conference        17539 non-null int64\n",
      "degree                17539 non-null float64\n",
      "pagerank              17539 non-null float64\n",
      "degree_centrality     17539 non-null float64\n",
      "diff_year             17539 non-null float64\n",
      "coauthors_top10000    17539 non-null int64\n",
      "coauthors_top20000    17539 non-null int64\n",
      "coauthors_top30000    17539 non-null int64\n",
      "category              17539 non-null int64\n",
      "label                 17539 non-null int64\n",
      "dtypes: float64(6), int64(15)\n",
      "memory usage: 2.9 MB\n",
      "train_data.info():: None\n",
      "shape of test_data:: (833, 21)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 833 entries, 0 to 849\n",
      "Data columns (total 21 columns):\n",
      "bys_cn                833 non-null float64\n",
      "hindex_cn             833 non-null int64\n",
      "a_paper               833 non-null int64\n",
      "b_paper               833 non-null int64\n",
      "c_paper               833 non-null int64\n",
      "papernum2017          833 non-null int64\n",
      "papernum2016          833 non-null int64\n",
      "papernum2015          833 non-null int64\n",
      "papernum2014          833 non-null int64\n",
      "papernum2013          833 non-null int64\n",
      "num_journal           833 non-null int64\n",
      "num_conference        833 non-null int64\n",
      "degree                833 non-null float64\n",
      "pagerank              833 non-null float64\n",
      "degree_centrality     833 non-null float64\n",
      "diff_year             833 non-null float64\n",
      "coauthors_top10000    833 non-null int64\n",
      "coauthors_top20000    833 non-null int64\n",
      "coauthors_top30000    833 non-null int64\n",
      "category              833 non-null int64\n",
      "label                 833 non-null int64\n",
      "dtypes: float64(5), int64(16)\n",
      "memory usage: 143.2 KB\n",
      "test_data.info():: None\n",
      "y_test_label:: Counter({0: 683, 1: 150})\n"
     ]
    }
   ],
   "source": [
    "# 对缺失值进行处理\n",
    "# Method1：直接将含有缺失字段的值去掉\n",
    "train_data = train_data.dropna()\n",
    "print(\"shape of train_data::\", train_data.shape)\n",
    "print(\"train_data.info()::\", train_data.info())\n",
    "test_data = test_data.dropna()\n",
    "print(\"shape of test_data::\", test_data.shape)\n",
    "print(\"test_data.info()::\", test_data.info())\n",
    "print(\"y_test_label::\", Counter(test_data[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** (17539, 20)\n",
      "17539   20\n",
      "info of X_train: (17539, 22)\n",
      "y_train:: Counter({1: 16551, 0: 988})\n",
      "833   20\n",
      "info of X_test: (833, 22)\n",
      "y_test:: Counter({0: 683, 1: 150})\n"
     ]
    }
   ],
   "source": [
    "# 将category变成离散值（object），并将train_data变成向量（离散值变成one-hot）\n",
    "\n",
    "# training data\n",
    "train_data[['category']] = train_data[['category']].astype(object)\n",
    "y_train = train_data['label']\n",
    "X_train = train_data.drop(columns=['label'])\n",
    "print(\"****\", X_train.shape)\n",
    "\n",
    "vec = DictVectorizer()   \n",
    "\n",
    "# 因为fDictVectorizer().fit_transform()需要的参数时list of dict，所以这里将其转化\n",
    "headers_train = list(X_train.columns)\n",
    "value_df_train = X_train.values\n",
    "feature_list_train = []\n",
    "for value_train in value_df_train:\n",
    "    feature_dict = {}\n",
    "    for i in range(0, len(headers_train)):\n",
    "        if headers_train[i]=='category':\n",
    "            feature_dict[headers_train[i]] = str(value_train[i])\n",
    "        else:\n",
    "            feature_dict[headers_train[i]] = value_train[i]\n",
    "    feature_list_train.append(feature_dict)\n",
    "print(len(feature_list_train), ' ', len(feature_list_train[0]))\n",
    "\n",
    "X_train = vec.fit_transform(feature_list_train)\n",
    "print(\"info of X_train:\", X_train.shape)\n",
    "print(\"y_train::\", Counter(y_train))\n",
    "\n",
    "# testing data\n",
    "test_data[['category']] = test_data[['category']].astype(object)\n",
    "y_test = test_data['label']\n",
    "X_test = test_data.drop(columns=['label'])\n",
    "\n",
    "headers_test = list(X_test.columns)\n",
    "value_df_test = X_test.values\n",
    "# print(headers)\n",
    "# print(value_df.shape)\n",
    "feature_list_test = []\n",
    "for value_test in value_df_test:\n",
    "    feature_dict = {}\n",
    "    for i in range(0, len(headers_test)):\n",
    "        if headers_test[i]=='category':\n",
    "            feature_dict[headers_test[i]] = str(value_test[i])\n",
    "        else:\n",
    "            feature_dict[headers_test[i]] = value_test[i]\n",
    "    feature_list_test.append(feature_dict)\n",
    "print(len(feature_list_test), ' ', len(feature_list_test[0]))\n",
    "\n",
    "X_test = vec.transform(feature_list_test)\n",
    "print(\"info of X_test:\", X_test.shape)\n",
    "print(\"y_test::\", Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、获取需要预测的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data_test: (181057, 20)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 181057 entries, 0 to 181056\n",
      "Data columns (total 20 columns):\n",
      "bys_cn                176811 non-null float64\n",
      "hindex_cn             180624 non-null float64\n",
      "a_paper               181057 non-null int64\n",
      "b_paper               181057 non-null int64\n",
      "c_paper               181057 non-null int64\n",
      "papernum2017          181057 non-null int64\n",
      "papernum2016          181057 non-null int64\n",
      "papernum2015          181057 non-null int64\n",
      "papernum2014          181057 non-null int64\n",
      "papernum2013          181057 non-null int64\n",
      "num_journal           181057 non-null int64\n",
      "num_conference        181057 non-null int64\n",
      "degree                180847 non-null float64\n",
      "pagerank              180847 non-null float64\n",
      "degree_centrality     180847 non-null float64\n",
      "diff_year             180847 non-null float64\n",
      "coauthors_top10000    181057 non-null int64\n",
      "coauthors_top20000    181057 non-null int64\n",
      "coauthors_top30000    181057 non-null int64\n",
      "category              181057 non-null int64\n",
      "dtypes: float64(6), int64(14)\n",
      "memory usage: 27.6 MB\n",
      "data_test.info(): None\n"
     ]
    }
   ],
   "source": [
    "def get_predict_data(connection):\n",
    "    \"\"\"\n",
    "    获取需要预测的数据，包括训练集中的特征\n",
    "    :param connection:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    sql_select = \"\"\"\n",
    "    SELECT bys_cn, hindex_cn,a_conf+a_journal as a_paper, b_conf + b_journal as b_paper,c_conf + c_journal as c_paper,papernum2017, papernum2016, papernum2015, papernum2014, papernum2013,num_journal,num_conference, project_num, degree, pagerank,degree_centrality,last_year - first_year as diff_year , coauthors_top10000, coauthors_top20000, coauthors_top30000, category \n",
    "    FROM classifier_isTeacher_xgbc WHERE label is null and category is not null\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(sql_select, connection)\n",
    "    all_features = ['bys_cn', 'hindex_cn', 'a_paper', 'b_paper', 'c_paper', 'papernum2017', 'papernum2016', 'papernum2015', 'papernum2014', 'papernum2013', 'num_journal', 'num_conference',  'degree', 'pagerank', 'degree_centrality', 'diff_year', 'coauthors_top10000', 'coauthors_top20000', 'coauthors_top30000', 'category']\n",
    "    data = df[all_features]\n",
    "    return data\n",
    "\n",
    "data_test = get_predict_data(connection)\n",
    "print(\"shape of data_test:\", data_test.shape)\n",
    "print(\"data_test.info():\", data_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、处理需要预测的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 181057 entries, 0 to 181056\n",
      "Data columns (total 20 columns):\n",
      "bys_cn                181057 non-null float64\n",
      "hindex_cn             181057 non-null float64\n",
      "a_paper               181057 non-null int64\n",
      "b_paper               181057 non-null int64\n",
      "c_paper               181057 non-null int64\n",
      "papernum2017          181057 non-null int64\n",
      "papernum2016          181057 non-null int64\n",
      "papernum2015          181057 non-null int64\n",
      "papernum2014          181057 non-null int64\n",
      "papernum2013          181057 non-null int64\n",
      "num_journal           181057 non-null int64\n",
      "num_conference        181057 non-null int64\n",
      "degree                181057 non-null float64\n",
      "pagerank              181057 non-null float64\n",
      "degree_centrality     181057 non-null float64\n",
      "diff_year             181057 non-null float64\n",
      "coauthors_top10000    181057 non-null int64\n",
      "coauthors_top20000    181057 non-null int64\n",
      "coauthors_top30000    181057 non-null int64\n",
      "category              181057 non-null int64\n",
      "dtypes: float64(6), int64(14)\n",
      "memory usage: 27.6 MB\n",
      "info of data_test_fill:: None\n",
      "181057   20\n",
      "shape of X_test_all:: (181057, 22)\n"
     ]
    }
   ],
   "source": [
    "# 使用0进行填充\n",
    "data_test_fill = data_test.fillna(0)\n",
    "print(\"info of data_test_fill::\", data_test_fill.info())\n",
    "\n",
    "# 因为fDictVectorizer().fit_transform()需要的参数时list of dict，所以这里将其转化\n",
    "headers_test_all = list(data_test_fill.columns)\n",
    "value_df_train_all = data_test_fill.values\n",
    "feature_list_train_all = []\n",
    "for value_test_all in value_df_train_all:\n",
    "    feature_dict = {}\n",
    "    for i in range(0, len(headers_test_all)):\n",
    "        if headers_test_all[i]=='category':\n",
    "            feature_dict[headers_test_all[i]] = str(value_test_all[i])\n",
    "        else:\n",
    "            feature_dict[headers_test_all[i]] = value_test_all[i]\n",
    "    feature_list_train_all.append(feature_dict)\n",
    "print(len(feature_list_train_all), ' ', len(feature_list_train_all[0]))\n",
    "\n",
    "X_test_all = vec.transform(feature_list_train_all)\n",
    "\n",
    "print(\"shape of X_test_all::\", X_test_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5、Filter方法\n",
    "\n",
    "（1）特征选择使用方差分析\n",
    "\n",
    "（2）分类器使用XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************threshold is::0.000000******************\n",
      "接收到的threshold是：0\n",
      "X_train.shape (17539, 22)\n",
      "X_test.shape (833, 22)\n",
      "[2.56106580e+01 2.25313360e+01 4.17984507e+05 7.58498276e+01\n",
      " 2.42543605e-01 1.86447944e-01 2.23900224e-01 2.43022507e+00\n",
      " 5.05146466e+00 7.85393791e+00 1.08043618e+04 8.21636764e+01\n",
      " 4.72188995e+01 2.53833987e+01 6.17049224e+02 2.90248006e+03\n",
      " 2.16394958e+02 2.54135433e+01 2.82871362e+01]\n",
      "shape of X_continuous_train_new:: (17539, 19)\n",
      "type of X_continuous_train_new:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_train_new:: (17539, 19)\n",
      "shape of X_train:: (17539, 22)\n",
      "[2.56106580e+01 2.25313360e+01 4.17984507e+05 7.58498276e+01\n",
      " 2.42543605e-01 1.86447944e-01 2.23900224e-01 2.43022507e+00\n",
      " 5.05146466e+00 7.85393791e+00 1.08043618e+04 8.21636764e+01\n",
      " 4.72188995e+01 2.53833987e+01 6.17049224e+02 2.90248006e+03\n",
      " 2.16394958e+02 2.54135433e+01 2.82871362e+01]\n",
      "shape of X_continuous_test_new:: (833, 19)\n",
      "type of X_continuous_test_new:: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "shape of X_continuous_test_new:: (833, 19)\n",
      "shape of X_test:: (833, 22)\n",
      "shape of X_train:: (17539, 22)\n",
      "shape of X_test:: (833, 22)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.65447   1.00000   0.79115       447\n",
      "           1    1.00000   0.38860   0.55970       386\n",
      "\n",
      "   micro avg    0.71669   0.71669   0.71669       833\n",
      "   macro avg    0.82723   0.69430   0.67543       833\n",
      "weighted avg    0.81458   0.71669   0.68390       833\n",
      "\n",
      "\n",
      "**************threshold is::2.000000******************\n",
      "接收到的threshold是：2\n",
      "X_train.shape (17539, 22)\n",
      "X_test.shape (833, 22)\n",
      "[2.56106580e+01 2.25313360e+01 4.17984507e+05 7.58498276e+01\n",
      " 2.42543605e-01 1.86447944e-01 2.23900224e-01 2.43022507e+00\n",
      " 5.05146466e+00 7.85393791e+00 1.08043618e+04 8.21636764e+01\n",
      " 4.72188995e+01 2.53833987e+01 6.17049224e+02 2.90248006e+03\n",
      " 2.16394958e+02 2.54135433e+01 2.82871362e+01]\n",
      "shape of X_continuous_train_new:: (17539, 16)\n",
      "type of X_continuous_train_new:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_train_new:: (17539, 16)\n",
      "shape of X_train:: (17539, 19)\n",
      "[2.56106580e+01 2.25313360e+01 4.17984507e+05 7.58498276e+01\n",
      " 2.42543605e-01 1.86447944e-01 2.23900224e-01 2.43022507e+00\n",
      " 5.05146466e+00 7.85393791e+00 1.08043618e+04 8.21636764e+01\n",
      " 4.72188995e+01 2.53833987e+01 6.17049224e+02 2.90248006e+03\n",
      " 2.16394958e+02 2.54135433e+01 2.82871362e+01]\n",
      "shape of X_continuous_test_new:: (833, 16)\n",
      "type of X_continuous_test_new:: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "shape of X_continuous_test_new:: (833, 16)\n",
      "shape of X_test:: (833, 19)\n",
      "shape of X_train:: (17539, 19)\n",
      "shape of X_test:: (833, 19)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.63250   1.00000   0.77489       432\n",
      "           1    1.00000   0.37406   0.54446       401\n",
      "\n",
      "   micro avg    0.69868   0.69868   0.69868       833\n",
      "   macro avg    0.81625   0.68703   0.65968       833\n",
      "weighted avg    0.80941   0.69868   0.66396       833\n",
      "\n",
      "\n",
      "**************threshold is::4.000000******************\n",
      "接收到的threshold是：4\n",
      "X_train.shape (17539, 22)\n",
      "X_test.shape (833, 22)\n",
      "[2.56106580e+01 2.25313360e+01 4.17984507e+05 7.58498276e+01\n",
      " 2.42543605e-01 1.86447944e-01 2.23900224e-01 2.43022507e+00\n",
      " 5.05146466e+00 7.85393791e+00 1.08043618e+04 8.21636764e+01\n",
      " 4.72188995e+01 2.53833987e+01 6.17049224e+02 2.90248006e+03\n",
      " 2.16394958e+02 2.54135433e+01 2.82871362e+01]\n",
      "shape of X_continuous_train_new:: (17539, 15)\n",
      "type of X_continuous_train_new:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_train_new:: (17539, 15)\n",
      "shape of X_train:: (17539, 18)\n",
      "[2.56106580e+01 2.25313360e+01 4.17984507e+05 7.58498276e+01\n",
      " 2.42543605e-01 1.86447944e-01 2.23900224e-01 2.43022507e+00\n",
      " 5.05146466e+00 7.85393791e+00 1.08043618e+04 8.21636764e+01\n",
      " 4.72188995e+01 2.53833987e+01 6.17049224e+02 2.90248006e+03\n",
      " 2.16394958e+02 2.54135433e+01 2.82871362e+01]\n",
      "shape of X_continuous_test_new:: (833, 15)\n",
      "type of X_continuous_test_new:: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "shape of X_continuous_test_new:: (833, 15)\n",
      "shape of X_test:: (833, 18)\n",
      "shape of X_train:: (17539, 18)\n",
      "shape of X_test:: (833, 18)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.63543   1.00000   0.77708       434\n",
      "           1    1.00000   0.37594   0.54645       399\n",
      "\n",
      "   micro avg    0.70108   0.70108   0.70108       833\n",
      "   macro avg    0.81772   0.68797   0.66176       833\n",
      "weighted avg    0.81006   0.70108   0.66661       833\n",
      "\n",
      "\n",
      "**************threshold is::6.000000******************\n",
      "接收到的threshold是：6\n",
      "X_train.shape (17539, 22)\n",
      "X_test.shape (833, 22)\n",
      "[2.56106580e+01 2.25313360e+01 4.17984507e+05 7.58498276e+01\n",
      " 2.42543605e-01 1.86447944e-01 2.23900224e-01 2.43022507e+00\n",
      " 5.05146466e+00 7.85393791e+00 1.08043618e+04 8.21636764e+01\n",
      " 4.72188995e+01 2.53833987e+01 6.17049224e+02 2.90248006e+03\n",
      " 2.16394958e+02 2.54135433e+01 2.82871362e+01]\n",
      "shape of X_continuous_train_new:: (17539, 14)\n",
      "type of X_continuous_train_new:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_train_new:: (17539, 14)\n",
      "shape of X_train:: (17539, 17)\n",
      "[2.56106580e+01 2.25313360e+01 4.17984507e+05 7.58498276e+01\n",
      " 2.42543605e-01 1.86447944e-01 2.23900224e-01 2.43022507e+00\n",
      " 5.05146466e+00 7.85393791e+00 1.08043618e+04 8.21636764e+01\n",
      " 4.72188995e+01 2.53833987e+01 6.17049224e+02 2.90248006e+03\n",
      " 2.16394958e+02 2.54135433e+01 2.82871362e+01]\n",
      "shape of X_continuous_test_new:: (833, 14)\n",
      "type of X_continuous_test_new:: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "shape of X_continuous_test_new:: (833, 14)\n",
      "shape of X_test:: (833, 17)\n",
      "shape of X_train:: (17539, 17)\n",
      "shape of X_test:: (833, 17)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.62811   1.00000   0.77158       429\n",
      "           1    1.00000   0.37129   0.54152       404\n",
      "\n",
      "   micro avg    0.69508   0.69508   0.69508       833\n",
      "   macro avg    0.81406   0.68564   0.65655       833\n",
      "weighted avg    0.80848   0.69508   0.66000       833\n",
      "\n",
      "\n",
      "**************threshold is::8.000000******************\n",
      "接收到的threshold是：8\n",
      "X_train.shape (17539, 22)\n",
      "X_test.shape (833, 22)\n",
      "[2.56106580e+01 2.25313360e+01 4.17984507e+05 7.58498276e+01\n",
      " 2.42543605e-01 1.86447944e-01 2.23900224e-01 2.43022507e+00\n",
      " 5.05146466e+00 7.85393791e+00 1.08043618e+04 8.21636764e+01\n",
      " 4.72188995e+01 2.53833987e+01 6.17049224e+02 2.90248006e+03\n",
      " 2.16394958e+02 2.54135433e+01 2.82871362e+01]\n",
      "shape of X_continuous_train_new:: (17539, 13)\n",
      "type of X_continuous_train_new:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_train_new:: (17539, 13)\n",
      "shape of X_train:: (17539, 16)\n",
      "[2.56106580e+01 2.25313360e+01 4.17984507e+05 7.58498276e+01\n",
      " 2.42543605e-01 1.86447944e-01 2.23900224e-01 2.43022507e+00\n",
      " 5.05146466e+00 7.85393791e+00 1.08043618e+04 8.21636764e+01\n",
      " 4.72188995e+01 2.53833987e+01 6.17049224e+02 2.90248006e+03\n",
      " 2.16394958e+02 2.54135433e+01 2.82871362e+01]\n",
      "shape of X_continuous_test_new:: (833, 13)\n",
      "type of X_continuous_test_new:: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "shape of X_continuous_test_new:: (833, 13)\n",
      "shape of X_test:: (833, 16)\n",
      "shape of X_train:: (17539, 16)\n",
      "shape of X_test:: (833, 16)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.63250   1.00000   0.77489       432\n",
      "           1    1.00000   0.37406   0.54446       401\n",
      "\n",
      "   micro avg    0.69868   0.69868   0.69868       833\n",
      "   macro avg    0.81625   0.68703   0.65968       833\n",
      "weighted avg    0.80941   0.69868   0.66396       833\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_XGBC_var_select(X_train, y_train, X_test, y_test, var_threshold):\n",
    "    \n",
    "    print(\"接收到的threshold是：%d\" % var_threshold)\n",
    "    \n",
    "    print(\"X_train.shape\", X_train.shape)\n",
    "    print(\"X_test.shape\", X_test.shape)\n",
    "    \n",
    "    # 方差选择，只选择连续特征，离散特征不做选择\n",
    "    vt = VarianceThreshold(threshold=var_threshold)\n",
    "    X_continuous_train_new = vt.fit_transform(X_train[:, 0:-3].A)\n",
    "    print(vt.variances_)\n",
    "    print(\"shape of X_continuous_train_new::\", X_continuous_train_new.shape)\n",
    "\n",
    "    # 归一化\n",
    "    ss = StandardScaler(with_mean=False)\n",
    "    X_continuous_train_new = ss.fit_transform(X_continuous_train_new)\n",
    "    print(\"type of X_continuous_train_new::\", type(X_continuous_train_new))\n",
    "    print(\"shape of X_continuous_train_new::\", X_continuous_train_new.shape)\n",
    "\n",
    "    # 将连续值和离散值拼接\n",
    "    X_train = np.hstack((X_continuous_train_new, X_train[:, -3:].A))   # .A转化为.numpy.ndarray\n",
    "    print(\"shape of X_train::\", X_train.shape)\n",
    "    \n",
    "     # 方差选择，只选择连续特征，离散特征不做选择\n",
    "    X_continuous_test_new = vt.transform(X_test[:, 0:-3])\n",
    "    print(vt.variances_)\n",
    "    print(\"shape of X_continuous_test_new::\", X_continuous_test_new.shape)\n",
    "\n",
    "    # 归一化\n",
    "    X_continuous_test_new = ss.transform(X_continuous_test_new)\n",
    "    print(\"type of X_continuous_test_new::\", type(X_continuous_test_new))\n",
    "    print(\"shape of X_continuous_test_new::\", X_continuous_test_new.shape)\n",
    "\n",
    "    # 将连续值和离散值拼接\n",
    "    X_test = np.hstack((X_continuous_test_new.A, X_test[:, -3:].A))\n",
    "    print(\"shape of X_test::\", X_test.shape)\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    print(\"shape of X_train::\", X_train.shape)\n",
    "    print(\"shape of X_test::\", X_test.shape)\n",
    "    print(\"shape of y_train::\", y_train.shape)\n",
    "    print(\"Counter of y_train::\", Counter(y_train))\n",
    "    print(\"shape of y_test::\", y_test.shape)\n",
    "    print(\"Counter of y_test::\", Counter(y_test))\n",
    "    \n",
    "    \n",
    "    xgbc = XGBClassifier()\n",
    "    xgbc.fit(X_train, y_train)\n",
    "    y_test_predict = xgbc.predict(X_test)\n",
    "    print(classification_report(y_test_predict, y_test, target_names=['0', '1'], digits=5))\n",
    "    \n",
    "\n",
    "# 网格搜索 \n",
    "for var_threshold in range(0, 10, 2):\n",
    "    X_train_copy = deepcopy(X_train)    \n",
    "    X_test_copy = deepcopy(X_test)\n",
    "    y_train_copy = deepcopy(y_train)\n",
    "    y_test_copy = deepcopy(y_test)\n",
    "    print()\n",
    "    print(\"**************threshold is::%f******************\" % var_threshold)\n",
    "    train_XGBC_var_select(X_train_copy, y_train_copy, X_test_copy, y_test_copy, var_threshold)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "接收到的threshold是：0\n",
      "X_train.shape (17539, 22)\n",
      "X_test.shape (833, 22)\n",
      "[2.56106580e+01 2.25313360e+01 4.17984507e+05 7.58498276e+01\n",
      " 2.42543605e-01 1.86447944e-01 2.23900224e-01 2.43022507e+00\n",
      " 5.05146466e+00 7.85393791e+00 1.08043618e+04 8.21636764e+01\n",
      " 4.72188995e+01 2.53833987e+01 6.17049224e+02 2.90248006e+03\n",
      " 2.16394958e+02 2.54135433e+01 2.82871362e+01]\n",
      "shape of X_continuous_train_new:: (17539, 19)\n",
      "type of X_continuous_train_new:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_train_new:: (17539, 19)\n",
      "shape of X_train:: (17539, 22)\n",
      "[2.56106580e+01 2.25313360e+01 4.17984507e+05 7.58498276e+01\n",
      " 2.42543605e-01 1.86447944e-01 2.23900224e-01 2.43022507e+00\n",
      " 5.05146466e+00 7.85393791e+00 1.08043618e+04 8.21636764e+01\n",
      " 4.72188995e+01 2.53833987e+01 6.17049224e+02 2.90248006e+03\n",
      " 2.16394958e+02 2.54135433e+01 2.82871362e+01]\n",
      "shape of X_continuous_test_new:: (833, 19)\n",
      "type of X_continuous_test_new:: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "shape of X_continuous_test_new:: (833, 19)\n",
      "shape of X_test:: (833, 22)\n",
      "shape of X_train:: (17539, 22)\n",
      "shape of X_test:: (833, 22)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.65447   1.00000   0.79115       447\n",
      "           1    1.00000   0.38860   0.55970       386\n",
      "\n",
      "   micro avg    0.71669   0.71669   0.71669       833\n",
      "   macro avg    0.82723   0.69430   0.67543       833\n",
      "weighted avg    0.81458   0.71669   0.68390       833\n",
      "\n",
      "[2.56106580e+01 2.25313360e+01 4.17984507e+05 7.58498276e+01\n",
      " 2.42543605e-01 1.86447944e-01 2.23900224e-01 2.43022507e+00\n",
      " 5.05146466e+00 7.85393791e+00 1.08043618e+04 8.21636764e+01\n",
      " 4.72188995e+01 2.53833987e+01 6.17049224e+02 2.90248006e+03\n",
      " 2.16394958e+02 2.54135433e+01 2.82871362e+01]\n",
      "shape of X_continuous_test_all:: (181057, 19)\n",
      "type of X_continuous_test_all:: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "shape of X_continuous_test_all:: (181057, 19)\n",
      "shape::: (181057, 3)\n",
      "shape of X_test:: (181057, 22)\n",
      "y_predict:: Counter({1: 119240, 0: 61817})\n"
     ]
    }
   ],
   "source": [
    "# 若是特征非常多，则可以考虑去除对性能影响最小的特征。这里特征不是很多，不在进行去除，只是为了再熟悉下流程，这里写了一遍方差分析。\n",
    "def train_and_test_XGBC_var_select(X_train, y_train, X_test, y_test, X_test_all, var_threshold = 0):\n",
    "    \n",
    "    print(\"接收到的threshold是：%d\" % var_threshold)\n",
    "    \n",
    "    print(\"X_train.shape\", X_train.shape)\n",
    "    print(\"X_test.shape\", X_test.shape)\n",
    "    \n",
    "    # 方差选择，只选择连续特征，离散特征不做选择\n",
    "    vt = VarianceThreshold(threshold=var_threshold)\n",
    "    X_continuous_train_new = vt.fit_transform(X_train[:, 0:-3].A)\n",
    "    print(vt.variances_)\n",
    "    print(\"shape of X_continuous_train_new::\", X_continuous_train_new.shape)\n",
    "\n",
    "    # 归一化\n",
    "    ss = StandardScaler(with_mean=False)\n",
    "    X_continuous_train_new = ss.fit_transform(X_continuous_train_new)\n",
    "    print(\"type of X_continuous_train_new::\", type(X_continuous_train_new))\n",
    "    print(\"shape of X_continuous_train_new::\", X_continuous_train_new.shape)\n",
    "\n",
    "    # 将连续值和离散值拼接\n",
    "    X_train = np.hstack((X_continuous_train_new, X_train[:, -3:].A))   # .A转化为.numpy.ndarray\n",
    "    print(\"shape of X_train::\", X_train.shape)\n",
    "    \n",
    "     # 方差选择，只选择连续特征，离散特征不做选择\n",
    "    X_continuous_test_new = vt.transform(X_test[:, 0:-3])\n",
    "    print(vt.variances_)\n",
    "    print(\"shape of X_continuous_test_new::\", X_continuous_test_new.shape)\n",
    "\n",
    "    # 归一化\n",
    "    X_continuous_test_new = ss.transform(X_continuous_test_new)\n",
    "    print(\"type of X_continuous_test_new::\", type(X_continuous_test_new))\n",
    "    print(\"shape of X_continuous_test_new::\", X_continuous_test_new.shape)\n",
    "\n",
    "    # 将连续值和离散值拼接\n",
    "    X_test = np.hstack((X_continuous_test_new.A, X_test[:, -3:].A))\n",
    "    print(\"shape of X_test::\", X_test.shape)\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    print(\"shape of X_train::\", X_train.shape)\n",
    "    print(\"shape of X_test::\", X_test.shape)\n",
    "    print(\"shape of y_train::\", y_train.shape)\n",
    "    print(\"Counter of y_train::\", Counter(y_train))\n",
    "    print(\"shape of y_test::\", y_test.shape)\n",
    "    print(\"Counter of y_test::\", Counter(y_test))\n",
    "    \n",
    "    \n",
    "    xgbc = XGBClassifier()\n",
    "    xgbc.fit(X_train, y_train)\n",
    "    y_test_predict = xgbc.predict(X_test)\n",
    "    print(classification_report(y_test_predict, y_test, target_names=['0', '1'], digits=5))\n",
    "    \n",
    "    \n",
    "    # 测试集上，方差选择，只选择连续特征，离散特征不做选择\n",
    "    X_continuous_test_all = vt.transform(X_test_all[:, 0:-3])\n",
    "    print(vt.variances_)\n",
    "    print(\"shape of X_continuous_test_all::\", X_continuous_test_all.shape)\n",
    "\n",
    "    # 归一化\n",
    "    X_continuous_test_all = ss.transform(X_continuous_test_all)\n",
    "    print(\"type of X_continuous_test_all::\", type(X_continuous_test_all))\n",
    "    print(\"shape of X_continuous_test_all::\", X_continuous_test_all.shape)\n",
    "    \n",
    "    # 将连续值和离散值拼接\n",
    "    print(\"shape:::\", X_test_all[:, -3:].shape)\n",
    "    X_test_all = np.hstack((X_continuous_test_all.A, X_test_all[:, -3:].A))\n",
    "    print(\"shape of X_test::\", X_test_all.shape)\n",
    "    \n",
    "    y_predict = xgbc.predict(X_test_all)\n",
    "    print(\"y_predict::\", Counter(y_predict))\n",
    "    \n",
    "# 调用预测函数\n",
    "X_train_copy = deepcopy(X_train)    \n",
    "X_test_copy = deepcopy(X_test)\n",
    "y_train_copy = deepcopy(y_train)\n",
    "y_test_copy = deepcopy(y_test)\n",
    "train_and_test_XGBC_var_select(X_train_copy, y_train_copy, X_test_copy, y_test_copy, X_test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6、Wrapper方法\n",
    "\n",
    "#### （1）RFE\n",
    "\n",
    "RFE和方差分析一样，去掉特征必然会带来性能的降低。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************n_features_to_select is::20.000000******************\n",
      "接收到的n_features_to_select是：20\n",
      "X_train.shape (17539, 22)\n",
      "X_test.shape (833, 22)\n",
      "selector.support_:: [ True  True  True  True  True False  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True False]\n",
      "[ 0  1  2  3  4  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "type of X_continuous_train_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_train_tmp:: (17539, 18)\n",
      "shape of X_train_new:: (17539, 19)\n",
      "type of X_continuous_test_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_test_tmp:: (833, 18)\n",
      "shape of X_test_new:: (833, 19)\n",
      "shape of X_train_new:: (17539, 19)\n",
      "shape of X_test_new:: (833, 19)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000         0\n",
      "           1    1.00000   0.18007   0.30519       833\n",
      "\n",
      "   micro avg    0.18007   0.18007   0.18007       833\n",
      "   macro avg    0.50000   0.09004   0.15259       833\n",
      "weighted avg    1.00000   0.18007   0.30519       833\n",
      "\n",
      "\n",
      "**************n_features_to_select is::19.000000******************\n",
      "接收到的n_features_to_select是：19\n",
      "X_train.shape (17539, 22)\n",
      "X_test.shape (833, 22)\n",
      "selector.support_:: [ True  True  True  True  True False  True  True  True  True  True  True\n",
      "  True  True  True  True  True False  True  True  True False]\n",
      "[ 0  1  2  3  4  6  7  8  9 10 11 12 13 14 15 16 18 19 20]\n",
      "type of X_continuous_train_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_train_tmp:: (17539, 17)\n",
      "shape of X_train_new:: (17539, 18)\n",
      "type of X_continuous_test_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_test_tmp:: (833, 17)\n",
      "shape of X_test_new:: (833, 18)\n",
      "shape of X_train_new:: (17539, 18)\n",
      "shape of X_test_new:: (833, 18)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000         0\n",
      "           1    1.00000   0.18007   0.30519       833\n",
      "\n",
      "   micro avg    0.18007   0.18007   0.18007       833\n",
      "   macro avg    0.50000   0.09004   0.15259       833\n",
      "weighted avg    1.00000   0.18007   0.30519       833\n",
      "\n",
      "\n",
      "**************n_features_to_select is::18.000000******************\n",
      "接收到的n_features_to_select是：18\n",
      "X_train.shape (17539, 22)\n",
      "X_test.shape (833, 22)\n",
      "selector.support_:: [ True  True  True  True  True False  True  True  True  True  True  True\n",
      "  True  True  True  True False False  True  True  True False]\n",
      "[ 0  1  2  3  4  6  7  8  9 10 11 12 13 14 15 18 19 20]\n",
      "type of X_continuous_train_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_train_tmp:: (17539, 16)\n",
      "shape of X_train_new:: (17539, 17)\n",
      "type of X_continuous_test_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_test_tmp:: (833, 16)\n",
      "shape of X_test_new:: (833, 17)\n",
      "shape of X_train_new:: (17539, 17)\n",
      "shape of X_test_new:: (833, 17)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000         0\n",
      "           1    1.00000   0.18007   0.30519       833\n",
      "\n",
      "   micro avg    0.18007   0.18007   0.18007       833\n",
      "   macro avg    0.50000   0.09004   0.15259       833\n",
      "weighted avg    1.00000   0.18007   0.30519       833\n",
      "\n",
      "\n",
      "**************n_features_to_select is::17.000000******************\n",
      "接收到的n_features_to_select是：17\n",
      "X_train.shape (17539, 22)\n",
      "X_test.shape (833, 22)\n",
      "selector.support_:: [ True  True  True  True  True False  True  True  True  True  True  True\n",
      "  True  True False  True False False  True  True  True False]\n",
      "[ 0  1  2  3  4  6  7  8  9 10 11 12 13 15 18 19 20]\n",
      "type of X_continuous_train_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_train_tmp:: (17539, 15)\n",
      "shape of X_train_new:: (17539, 16)\n",
      "type of X_continuous_test_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_test_tmp:: (833, 15)\n",
      "shape of X_test_new:: (833, 16)\n",
      "shape of X_train_new:: (17539, 16)\n",
      "shape of X_test_new:: (833, 16)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000         0\n",
      "           1    1.00000   0.18007   0.30519       833\n",
      "\n",
      "   micro avg    0.18007   0.18007   0.18007       833\n",
      "   macro avg    0.50000   0.09004   0.15259       833\n",
      "weighted avg    1.00000   0.18007   0.30519       833\n",
      "\n",
      "\n",
      "**************n_features_to_select is::16.000000******************\n",
      "接收到的n_features_to_select是：16\n",
      "X_train.shape (17539, 22)\n",
      "X_test.shape (833, 22)\n",
      "selector.support_:: [ True  True  True  True  True False  True  True  True  True  True  True\n",
      "  True  True False  True False False  True  True False False]\n",
      "[ 0  1  2  3  4  6  7  8  9 10 11 12 13 15 18 19]\n",
      "type of X_continuous_train_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_train_tmp:: (17539, 15)\n",
      "shape of X_train_new:: (17539, 17)\n",
      "type of X_continuous_test_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_test_tmp:: (833, 15)\n",
      "shape of X_test_new:: (833, 17)\n",
      "shape of X_train_new:: (17539, 17)\n",
      "shape of X_test_new:: (833, 17)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000         0\n",
      "           1    1.00000   0.18007   0.30519       833\n",
      "\n",
      "   micro avg    0.18007   0.18007   0.18007       833\n",
      "   macro avg    0.50000   0.09004   0.15259       833\n",
      "weighted avg    1.00000   0.18007   0.30519       833\n",
      "\n",
      "\n",
      "**************n_features_to_select is::15.000000******************\n",
      "接收到的n_features_to_select是：15\n",
      "X_train.shape (17539, 22)\n",
      "X_test.shape (833, 22)\n",
      "selector.support_:: [ True  True  True  True  True False  True  True  True  True  True  True\n",
      "  True  True False  True False False  True False False False]\n",
      "[ 0  1  2  3  4  6  7  8  9 10 11 12 13 15 18]\n",
      "type of X_continuous_train_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_train_tmp:: (17539, 15)\n",
      "shape of X_train_new:: (17539, 18)\n",
      "type of X_continuous_test_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_test_tmp:: (833, 15)\n",
      "shape of X_test_new:: (833, 18)\n",
      "shape of X_train_new:: (17539, 18)\n",
      "shape of X_test_new:: (833, 18)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000         0\n",
      "           1    1.00000   0.18007   0.30519       833\n",
      "\n",
      "   micro avg    0.18007   0.18007   0.18007       833\n",
      "   macro avg    0.50000   0.09004   0.15259       833\n",
      "weighted avg    1.00000   0.18007   0.30519       833\n",
      "\n",
      "\n",
      "**************n_features_to_select is::14.000000******************\n",
      "接收到的n_features_to_select是：14\n",
      "X_train.shape (17539, 22)\n",
      "X_test.shape (833, 22)\n",
      "selector.support_:: [ True False  True  True  True False  True  True  True  True  True  True\n",
      "  True  True False  True False False  True False False False]\n",
      "[ 0  2  3  4  6  7  8  9 10 11 12 13 15 18]\n",
      "type of X_continuous_train_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_train_tmp:: (17539, 14)\n",
      "shape of X_train_new:: (17539, 17)\n",
      "type of X_continuous_test_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_test_tmp:: (833, 14)\n",
      "shape of X_test_new:: (833, 17)\n",
      "shape of X_train_new:: (17539, 17)\n",
      "shape of X_test_new:: (833, 17)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000         0\n",
      "           1    1.00000   0.18007   0.30519       833\n",
      "\n",
      "   micro avg    0.18007   0.18007   0.18007       833\n",
      "   macro avg    0.50000   0.09004   0.15259       833\n",
      "weighted avg    1.00000   0.18007   0.30519       833\n",
      "\n",
      "\n",
      "**************n_features_to_select is::13.000000******************\n",
      "接收到的n_features_to_select是：13\n",
      "X_train.shape (17539, 22)\n",
      "X_test.shape (833, 22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selector.support_:: [ True False  True  True  True False  True  True  True  True  True False\n",
      "  True  True False  True False False  True False False False]\n",
      "[ 0  2  3  4  6  7  8  9 10 12 13 15 18]\n",
      "type of X_continuous_train_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_train_tmp:: (17539, 13)\n",
      "shape of X_train_new:: (17539, 16)\n",
      "type of X_continuous_test_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_test_tmp:: (833, 13)\n",
      "shape of X_test_new:: (833, 16)\n",
      "shape of X_train_new:: (17539, 16)\n",
      "shape of X_test_new:: (833, 16)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000         0\n",
      "           1    1.00000   0.18007   0.30519       833\n",
      "\n",
      "   micro avg    0.18007   0.18007   0.18007       833\n",
      "   macro avg    0.50000   0.09004   0.15259       833\n",
      "weighted avg    1.00000   0.18007   0.30519       833\n",
      "\n",
      "\n",
      "**************n_features_to_select is::12.000000******************\n",
      "接收到的n_features_to_select是：12\n",
      "X_train.shape (17539, 22)\n",
      "X_test.shape (833, 22)\n",
      "selector.support_:: [ True False False  True  True False  True  True  True  True  True False\n",
      "  True  True False  True False False  True False False False]\n",
      "[ 0  3  4  6  7  8  9 10 12 13 15 18]\n",
      "type of X_continuous_train_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_train_tmp:: (17539, 12)\n",
      "shape of X_train_new:: (17539, 15)\n",
      "type of X_continuous_test_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_test_tmp:: (833, 12)\n",
      "shape of X_test_new:: (833, 15)\n",
      "shape of X_train_new:: (17539, 15)\n",
      "shape of X_test_new:: (833, 15)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000         0\n",
      "           1    1.00000   0.18007   0.30519       833\n",
      "\n",
      "   micro avg    0.18007   0.18007   0.18007       833\n",
      "   macro avg    0.50000   0.09004   0.15259       833\n",
      "weighted avg    1.00000   0.18007   0.30519       833\n",
      "\n",
      "\n",
      "**************n_features_to_select is::11.000000******************\n",
      "接收到的n_features_to_select是：11\n",
      "X_train.shape (17539, 22)\n",
      "X_test.shape (833, 22)\n",
      "selector.support_:: [ True False False  True  True False  True False  True  True  True False\n",
      "  True  True False  True False False  True False False False]\n",
      "[ 0  3  4  6  8  9 10 12 13 15 18]\n",
      "type of X_continuous_train_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_train_tmp:: (17539, 11)\n",
      "shape of X_train_new:: (17539, 14)\n",
      "type of X_continuous_test_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_test_tmp:: (833, 11)\n",
      "shape of X_test_new:: (833, 14)\n",
      "shape of X_train_new:: (17539, 14)\n",
      "shape of X_test_new:: (833, 14)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000         0\n",
      "           1    1.00000   0.18007   0.30519       833\n",
      "\n",
      "   micro avg    0.18007   0.18007   0.18007       833\n",
      "   macro avg    0.50000   0.09004   0.15259       833\n",
      "weighted avg    1.00000   0.18007   0.30519       833\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_XGBC_rfe_select(X_train, y_train, X_test, y_test, n_features_to_select):\n",
    "    \n",
    "    print(\"接收到的n_features_to_select是：%d\" % n_features_to_select)\n",
    "    \n",
    "    print(\"X_train.shape\", X_train.shape)\n",
    "    print(\"X_test.shape\", X_test.shape)\n",
    "    \n",
    "    # RFE特征选择\n",
    "    estimator = XGBClassifier()\n",
    "    selector = RFE(estimator=estimator, n_features_to_select = n_features_to_select)\n",
    "    X_train_rfe = selector.fit_transform(X_train, y_train) \n",
    "    selected_idx = np.where(pd.Series(selector.support_)==True)[0]   # n_features_to_select个选择出来的特征，每一个特征为True\n",
    "    print(\"selector.support_::\", selector.support_)\n",
    "    \n",
    "    print(selected_idx)\n",
    "    \n",
    "    # 因为Wrapper离散特征和连续特征需要一起训练搜索特征子集，但是因为离散特征不需要标准化，所以这里需要将其分开\n",
    "    discrete_idx = list(set([19, 20, 21]) - set(selected_idx))   # 最后3列为离散值\n",
    "    X_continuous_train_tmp = X_train.A[:, list(set(selected_idx) - set([19, 20, 21]))]\n",
    "    X_discreate_train_tmp = X_train.A[:, discrete_idx]\n",
    "    \n",
    "    X_continuous_test_tmp = X_test.A[:, list(set(selected_idx) - set([19, 20, 21]))]\n",
    "    X_discreate_test_tmp = X_test.A[:, discrete_idx]\n",
    "    \n",
    "    # 归一化\n",
    "    ss = StandardScaler()\n",
    "    X_continuous_train_tmp = ss.fit_transform(X_continuous_train_tmp)\n",
    "    print(\"type of X_continuous_train_tmp::\", type(X_continuous_train_tmp))\n",
    "    print(\"shape of X_continuous_train_tmp::\", X_continuous_train_tmp.shape)\n",
    "\n",
    "    # 将连续值和离散值拼接\n",
    "    X_train_new = np.hstack((X_continuous_train_tmp, X_discreate_train_tmp))\n",
    "    print(\"shape of X_train_new::\", X_train_new.shape)\n",
    "    \n",
    "    # testing data 归一化\n",
    "    X_continuous_test_tmp = ss.fit_transform(X_continuous_test_tmp)\n",
    "    print(\"type of X_continuous_test_tmp::\", type(X_continuous_test_tmp))\n",
    "    print(\"shape of X_continuous_test_tmp::\", X_continuous_test_tmp.shape)\n",
    "\n",
    "    # 将连续值和离散值拼接\n",
    "    X_test_new = np.hstack((X_continuous_test_tmp, X_discreate_test_tmp))\n",
    "    print(\"shape of X_test_new::\", X_test_new.shape)\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    print(\"shape of X_train_new::\", X_train_new.shape)\n",
    "    print(\"shape of X_test_new::\", X_test_new.shape)\n",
    "    print(\"shape of y_train::\", y_train.shape)\n",
    "    print(\"Counter of y_train::\", Counter(y_train))\n",
    "    print(\"shape of y_test::\", y_test.shape)\n",
    "    print(\"Counter of y_test::\", Counter(y_test))\n",
    "    \n",
    "    xgbc = XGBClassifier()\n",
    "    xgbc.fit(X_train_new, y_train)\n",
    "    y_test_predict = xgbc.predict(X_test_new)\n",
    "    print(classification_report(y_test_predict, y_test, target_names=['0', '1'], digits=5))\n",
    "    \n",
    "for n_features_to_select in range(20, 10, -1):    # 连续特征共有19个\n",
    "    X_train_copy = deepcopy(X_train)    \n",
    "    X_test_copy = deepcopy(X_test)\n",
    "    y_train_copy = deepcopy(y_train)\n",
    "    y_test_copy = deepcopy(y_test)\n",
    "    print()\n",
    "    print(\"**************n_features_to_select is::%f******************\" % n_features_to_select)\n",
    "    train_XGBC_rfe_select(X_train_copy, y_train_copy, X_test_copy, y_test_copy, n_features_to_select)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************n_features_to_select is::11.000000******************\n",
      "接收到的n_features_to_select是：15\n",
      "X_train.shape (17539, 22)\n",
      "X_test.shape (833, 22)\n",
      "selector.support_:: [ True  True  True  True  True False  True  True  True  True  True  True\n",
      "  True  True False  True False False  True False False False]\n",
      "[ 0  1  2  3  4  6  7  8  9 10 11 12 13 15 18]\n",
      "type of X_continuous_train_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_train_tmp:: (17539, 15)\n",
      "shape of X_train_new:: (17539, 18)\n",
      "type of X_continuous_test_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_test_tmp:: (833, 15)\n",
      "shape of X_test_new:: (833, 18)\n",
      "type of X_continuous_test_all_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_test_all_tmp:: (181057, 15)\n",
      "shape of X_test_new_all:: (181057, 18)\n",
      "shape of X_train_new:: (17539, 18)\n",
      "shape of X_test_new:: (833, 18)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000         0\n",
      "           1    1.00000   0.18007   0.30519       833\n",
      "\n",
      "   micro avg    0.18007   0.18007   0.18007       833\n",
      "   macro avg    0.50000   0.09004   0.15259       833\n",
      "weighted avg    1.00000   0.18007   0.30519       833\n",
      "\n",
      "y_predict:: Counter({1: 181057})\n"
     ]
    }
   ],
   "source": [
    "# 从上面的分析过程可以知道，RFE没什么作用，这里取15\n",
    "def train_and_test_XGBC_rfe_select(X_train, y_train, X_test, y_test, X_test_all, n_features_to_select=15):\n",
    "    \n",
    "    print(\"接收到的n_features_to_select是：%d\" % n_features_to_select)\n",
    "    \n",
    "    print(\"X_train.shape\", X_train.shape)\n",
    "    print(\"X_test.shape\", X_test.shape)\n",
    "    \n",
    "    # RFE特征选择\n",
    "    estimator = XGBClassifier()\n",
    "    selector = RFE(estimator=estimator, n_features_to_select = n_features_to_select)\n",
    "    X_train_rfe = selector.fit_transform(X_train, y_train) \n",
    "    selected_idx = np.where(pd.Series(selector.support_)==True)[0]   # n_features_to_select个选择出来的特征，每一个特征为True\n",
    "    print(\"selector.support_::\", selector.support_)\n",
    "    \n",
    "    print(selected_idx)\n",
    "    \n",
    "    # 因为Wrapper离散特征和连续特征需要一起训练搜索特征子集，但是因为离散特征不需要标准化，所以这里需要将其分开\n",
    "    discrete_idx = list(set([19, 20, 21]) - set(selected_idx))   # 最后3列为离散值\n",
    "    X_continuous_train_tmp = X_train.A[:, list(set(selected_idx) - set([19, 20, 21]))]\n",
    "    X_discreate_train_tmp = X_train.A[:, discrete_idx]\n",
    "    \n",
    "    X_continuous_test_tmp = X_test.A[:, list(set(selected_idx) - set([19, 20, 21]))]\n",
    "    X_discreate_test_tmp = X_test.A[:, discrete_idx]\n",
    "    \n",
    "    X_continuous_test_all_tmp = X_test_all.A[:, list(set(selected_idx) - set([19, 20, 21]))]\n",
    "    X_discreate_test_all_tmp = X_test_all.A[:, discrete_idx]\n",
    "    \n",
    "    # 归一化\n",
    "    ss = StandardScaler()\n",
    "    X_continuous_train_tmp = ss.fit_transform(X_continuous_train_tmp)\n",
    "    print(\"type of X_continuous_train_tmp::\", type(X_continuous_train_tmp))\n",
    "    print(\"shape of X_continuous_train_tmp::\", X_continuous_train_tmp.shape)\n",
    "\n",
    "    # 将连续值和离散值拼接\n",
    "    X_train_new = np.hstack((X_continuous_train_tmp, X_discreate_train_tmp))\n",
    "    print(\"shape of X_train_new::\", X_train_new.shape)\n",
    "    \n",
    "    # testing data 归一化\n",
    "    X_continuous_test_tmp = ss.fit_transform(X_continuous_test_tmp)\n",
    "    print(\"type of X_continuous_test_tmp::\", type(X_continuous_test_tmp))\n",
    "    print(\"shape of X_continuous_test_tmp::\", X_continuous_test_tmp.shape)\n",
    "\n",
    "    # 将连续值和离散值拼接\n",
    "    X_test_new = np.hstack((X_continuous_test_tmp, X_discreate_test_tmp))\n",
    "    print(\"shape of X_test_new::\", X_test_new.shape)\n",
    "    \n",
    "    # new data 归一化\n",
    "    X_continuous_test_all_tmp = ss.fit_transform(X_continuous_test_all_tmp)\n",
    "    print(\"type of X_continuous_test_all_tmp::\", type(X_continuous_test_all_tmp))\n",
    "    print(\"shape of X_continuous_test_all_tmp::\", X_continuous_test_all_tmp.shape)\n",
    "\n",
    "    # 将连续值和离散值拼接\n",
    "    X_test_new_all = np.hstack((X_continuous_test_all_tmp, X_discreate_test_all_tmp))\n",
    "    print(\"shape of X_test_new_all::\", X_test_new_all.shape)\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    print(\"shape of X_train_new::\", X_train_new.shape)\n",
    "    print(\"shape of X_test_new::\", X_test_new.shape)\n",
    "    print(\"shape of y_train::\", y_train.shape)\n",
    "    print(\"Counter of y_train::\", Counter(y_train))\n",
    "    print(\"shape of y_test::\", y_test.shape)\n",
    "    print(\"Counter of y_test::\", Counter(y_test))\n",
    "    \n",
    "    xgbc = XGBClassifier()\n",
    "    xgbc.fit(X_train_new, y_train)\n",
    "    y_test_predict = xgbc.predict(X_test_new)\n",
    "    print(classification_report(y_test_predict, y_test, target_names=['0', '1'], digits=5))\n",
    "    \n",
    "    y_predict = xgbc.predict(X_test_new_all)\n",
    "    print(\"y_predict::\", Counter(y_predict))\n",
    "\n",
    "X_train_copy = deepcopy(X_train)    \n",
    "X_test_copy = deepcopy(X_test)\n",
    "y_train_copy = deepcopy(y_train)\n",
    "y_test_copy = deepcopy(y_test)\n",
    "X_test_all = deepcopy(X_test_all)\n",
    "print()\n",
    "print(\"**************n_features_to_select is::%f******************\" % n_features_to_select)\n",
    "train_and_test_XGBC_rfe_select(X_train_copy, y_train_copy, X_test_copy, y_test_copy, X_test_all, n_features_to_select=15)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6、Wrapper方法\n",
    "\n",
    "#### （2）RFECV\n",
    "\n",
    "使用交叉验证来保留最佳性能的特征。不过这里的交叉验证的数据集切割对象不再是行数据（样本），而是列数据（特征），同时学习器本身不变，最终得到不同特征对于score的重要程度，然后保留最佳的特征组合。其分割方式类似于随机森林中的列上子采样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************step is::1, n_splits::2 *****************\n",
      "Optimal number of features::12\n",
      "Ranking of features:: [ 1  4  2  1  1 11  1  1  1  1  1  3  1  1  7  1  8  9  1  5  6 10]\n",
      "selector.support_:: [ True False False  True  True False  True  True  True  True  True False\n",
      "  True  True False  True False False  True False False False]\n",
      "type of X_continuous_train_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_train_tmp:: (17539, 12)\n",
      "shape of X_train_new:: (17539, 15)\n",
      "type of X_continuous_test_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_test_tmp:: (833, 12)\n",
      "shape of X_test_new:: (833, 15)\n",
      "shape of X_train_new:: (17539, 15)\n",
      "shape of X_test_new:: (833, 15)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000         0\n",
      "           1    1.00000   0.18007   0.30519       833\n",
      "\n",
      "   micro avg    0.18007   0.18007   0.18007       833\n",
      "   macro avg    0.50000   0.09004   0.15259       833\n",
      "weighted avg    1.00000   0.18007   0.30519       833\n",
      "\n",
      "\n",
      "**************step is::3, n_splits::2 *****************\n",
      "Optimal number of features::13\n",
      "Ranking of features:: [1 2 1 1 1 4 1 1 1 1 1 2 1 1 4 1 3 3 1 2 3 4]\n",
      "selector.support_:: [ True False  True  True  True False  True  True  True  True  True False\n",
      "  True  True False  True False False  True False False False]\n",
      "type of X_continuous_train_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_train_tmp:: (17539, 13)\n",
      "shape of X_train_new:: (17539, 16)\n",
      "type of X_continuous_test_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_test_tmp:: (833, 13)\n",
      "shape of X_test_new:: (833, 16)\n",
      "shape of X_train_new:: (17539, 16)\n",
      "shape of X_test_new:: (833, 16)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000         0\n",
      "           1    1.00000   0.18007   0.30519       833\n",
      "\n",
      "   micro avg    0.18007   0.18007   0.18007       833\n",
      "   macro avg    0.50000   0.09004   0.15259       833\n",
      "weighted avg    1.00000   0.18007   0.30519       833\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_XGBC_rfecv_select(X_train, y_train, X_test, y_test, step=1, n_splits=3):\n",
    "    \n",
    "    # RFECV\n",
    "    estimator = XGBClassifier()\n",
    "    selector = RFECV(estimator=estimator, step = step, cv=StratifiedKFold(n_splits=n_splits), scoring=\"accuracy\")\n",
    "    X_train_rfecv = selector.fit_transform(X_train, y_train) \n",
    "    print(\"Optimal number of features::%d\" % selector.n_features_)\n",
    "    print(\"Ranking of features:: %s\" % selector.ranking_)\n",
    "    selected_idx = np.where(pd.Series(selector.support_)==True)[0]   # n_features_to_select个选择出来的特征，每一个特征为True\n",
    "    print(\"selector.support_::\", selector.support_)\n",
    "    \n",
    "    # 因为Wrapper离散特征和连续特征需要一起训练搜索特征子集，但是因为离散特征不需要标准化，所以这里需要将其分开\n",
    "    discrete_idx = list(set([19, 20, 21]) - set(selected_idx))   # 最后3列为离散值\n",
    "    X_continuous_train_tmp = X_train.A[:, list(set(selected_idx) - set([19, 20, 21]))]\n",
    "    X_discreate_train_tmp = X_train.A[:, discrete_idx]\n",
    "    \n",
    "    X_continuous_test_tmp = X_test.A[:, list(set(selected_idx) - set([19, 20, 21]))]\n",
    "    X_discreate_test_tmp = X_test.A[:, discrete_idx]\n",
    "    \n",
    "    # 归一化\n",
    "    ss = StandardScaler()\n",
    "    X_continuous_train_tmp = ss.fit_transform(X_continuous_train_tmp)\n",
    "    print(\"type of X_continuous_train_tmp::\", type(X_continuous_train_tmp))\n",
    "    print(\"shape of X_continuous_train_tmp::\", X_continuous_train_tmp.shape)\n",
    "\n",
    "    # 将连续值和离散值拼接\n",
    "    X_train_new = np.hstack((X_continuous_train_tmp, X_discreate_train_tmp))\n",
    "    print(\"shape of X_train_new::\", X_train_new.shape)\n",
    "    \n",
    "    # testing data 归一化\n",
    "    X_continuous_test_tmp = ss.fit_transform(X_continuous_test_tmp)\n",
    "    print(\"type of X_continuous_test_tmp::\", type(X_continuous_test_tmp))\n",
    "    print(\"shape of X_continuous_test_tmp::\", X_continuous_test_tmp.shape)\n",
    "\n",
    "    # 将连续值和离散值拼接\n",
    "    X_test_new = np.hstack((X_continuous_test_tmp, X_discreate_test_tmp))\n",
    "    print(\"shape of X_test_new::\", X_test_new.shape)\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    print(\"shape of X_train_new::\", X_train_new.shape)\n",
    "    print(\"shape of X_test_new::\", X_test_new.shape)\n",
    "    print(\"shape of y_train::\", y_train.shape)\n",
    "    print(\"Counter of y_train::\", Counter(y_train))\n",
    "    print(\"shape of y_test::\", y_test.shape)\n",
    "    print(\"Counter of y_test::\", Counter(y_test))\n",
    "    \n",
    "    xgbc = XGBClassifier()\n",
    "    xgbc.fit(X_train_new, y_train)\n",
    "    y_test_predict = xgbc.predict(X_test_new)\n",
    "    print(classification_report(y_test_predict, y_test, target_names=['0', '1'], digits=5))\n",
    "    \n",
    "for step in range(1, 5, 2):    # 连续特征共有19个\n",
    "    for n_splits in range(2, 4, 2):\n",
    "        X_train_copy = deepcopy(X_train)    \n",
    "        X_test_copy = deepcopy(X_test)\n",
    "        y_train_copy = deepcopy(y_train)\n",
    "        y_test_copy = deepcopy(y_test)\n",
    "        print()\n",
    "        print(\"**************step is::%d, n_splits::%d *****************\" % (step, n_splits))\n",
    "        train_XGBC_rfecv_select(X_train_copy, y_train_copy, X_test_copy, y_test_copy, step, n_splits)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features::9\n",
      "Ranking of features:: [ 1  7  5  2  1 14  1  4  1  1  1  6  1  1 10  1 11 12  3  8  9 13]\n",
      "selector.support_:: [ True False False False  True False  True False  True  True  True False\n",
      "  True  True False  True False False False False False False]\n",
      "type of X_continuous_train_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_train_tmp:: (17539, 9)\n",
      "shape of X_train_new:: (17539, 12)\n",
      "type of X_continuous_test_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_test_tmp:: (833, 9)\n",
      "shape of X_test_new:: (833, 12)\n",
      "shape of X_train_new:: (17539, 12)\n",
      "shape of X_test_new:: (833, 12)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000         0\n",
      "           1    1.00000   0.18007   0.30519       833\n",
      "\n",
      "   micro avg    0.18007   0.18007   0.18007       833\n",
      "   macro avg    0.50000   0.09004   0.15259       833\n",
      "weighted avg    1.00000   0.18007   0.30519       833\n",
      "\n",
      "type of X_continuous_test_all_tmp:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_test_all_tmp:: (181057, 9)\n",
      "shape of X_test_new_all:: (181057, 12)\n",
      "y_predict:: Counter({1: 181057})\n"
     ]
    }
   ],
   "source": [
    "# 通过观察可以发现，rfecv的效果也不是很好\n",
    "def train_and_test_XGBC_rfecv_select(X_train, y_train, X_test, y_test, X_test_all, step=1, n_splits=3):\n",
    "    \n",
    "    # RFECV\n",
    "    estimator = XGBClassifier()\n",
    "    selector = RFECV(estimator=estimator, step = step, cv=StratifiedKFold(n_splits=n_splits), scoring=\"accuracy\")\n",
    "    X_train_rfecv = selector.fit_transform(X_train, y_train) \n",
    "    print(\"Optimal number of features::%d\" % selector.n_features_)\n",
    "    print(\"Ranking of features:: %s\" % selector.ranking_)\n",
    "    selected_idx = np.where(pd.Series(selector.support_)==True)[0]   # n_features_to_select个选择出来的特征，每一个特征为True\n",
    "    print(\"selector.support_::\", selector.support_)\n",
    "    \n",
    "    # 因为Wrapper离散特征和连续特征需要一起训练搜索特征子集，但是因为离散特征不需要标准化，所以这里需要将其分开\n",
    "    discrete_idx = list(set([19, 20, 21]) - set(selected_idx))   # 最后3列为离散值\n",
    "    X_continuous_train_tmp = X_train.A[:, list(set(selected_idx) - set([19, 20, 21]))]\n",
    "    X_discreate_train_tmp = X_train.A[:, discrete_idx]\n",
    "    \n",
    "    X_continuous_test_tmp = X_test.A[:, list(set(selected_idx) - set([19, 20, 21]))]\n",
    "    X_discreate_test_tmp = X_test.A[:, discrete_idx]\n",
    "    \n",
    "    X_continuous_test_all_tmp = X_test_all.A[:, list(set(selected_idx) - set([19, 20, 21]))]\n",
    "    X_discreate_test_all_tmp = X_test_all.A[:, discrete_idx]\n",
    "    \n",
    "    # 归一化\n",
    "    ss = StandardScaler()\n",
    "    X_continuous_train_tmp = ss.fit_transform(X_continuous_train_tmp)\n",
    "    print(\"type of X_continuous_train_tmp::\", type(X_continuous_train_tmp))\n",
    "    print(\"shape of X_continuous_train_tmp::\", X_continuous_train_tmp.shape)\n",
    "\n",
    "    # 将连续值和离散值拼接\n",
    "    X_train_new = np.hstack((X_continuous_train_tmp, X_discreate_train_tmp))\n",
    "    print(\"shape of X_train_new::\", X_train_new.shape)\n",
    "    \n",
    "    # testing data 归一化\n",
    "    X_continuous_test_tmp = ss.fit_transform(X_continuous_test_tmp)\n",
    "    print(\"type of X_continuous_test_tmp::\", type(X_continuous_test_tmp))\n",
    "    print(\"shape of X_continuous_test_tmp::\", X_continuous_test_tmp.shape)\n",
    "\n",
    "    # 将连续值和离散值拼接\n",
    "    X_test_new = np.hstack((X_continuous_test_tmp, X_discreate_test_tmp))\n",
    "    print(\"shape of X_test_new::\", X_test_new.shape)\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    print(\"shape of X_train_new::\", X_train_new.shape)\n",
    "    print(\"shape of X_test_new::\", X_test_new.shape)\n",
    "    print(\"shape of y_train::\", y_train.shape)\n",
    "    print(\"Counter of y_train::\", Counter(y_train))\n",
    "    print(\"shape of y_test::\", y_test.shape)\n",
    "    print(\"Counter of y_test::\", Counter(y_test))\n",
    "    \n",
    "    xgbc = XGBClassifier()\n",
    "    xgbc.fit(X_train_new, y_train)\n",
    "    y_test_predict = xgbc.predict(X_test_new)\n",
    "    print(classification_report(y_test_predict, y_test, target_names=['0', '1'], digits=5))\n",
    "    \n",
    "    # new data 归一化\n",
    "    X_continuous_test_all_tmp = ss.fit_transform(X_continuous_test_all_tmp)\n",
    "    print(\"type of X_continuous_test_all_tmp::\", type(X_continuous_test_all_tmp))\n",
    "    print(\"shape of X_continuous_test_all_tmp::\", X_continuous_test_all_tmp.shape)\n",
    "\n",
    "    # 将连续值和离散值拼接\n",
    "    X_test_new_all = np.hstack((X_continuous_test_all_tmp, X_discreate_test_all_tmp))\n",
    "    print(\"shape of X_test_new_all::\", X_test_new_all.shape)\n",
    "    \n",
    "    y_predict = xgbc.predict(X_test_new_all)\n",
    "    print(\"y_predict::\", Counter(y_predict))\n",
    "    \n",
    "\n",
    "X_train_copy = deepcopy(X_train)    \n",
    "X_test_copy = deepcopy(X_test)\n",
    "y_train_copy = deepcopy(y_train)\n",
    "y_test_copy = deepcopy(y_test)\n",
    "X_test_all_copy = deepcopy(X_test_all)\n",
    "train_and_test_XGBC_rfecv_select(X_train_copy, y_train_copy, X_test_copy, y_test_copy, X_test_all_copy)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7、Embedded方法\n",
    "\n",
    "使用L1正则项实现特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************C is::1.000000*****************\n",
      "type of X_continuous_train_new:: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "shape of X_continuous_train_new:: (17539, 19)\n",
      "shape of X_train:: (17539, 22)\n",
      "type of X_continuous_test_new:: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "shape of X_continuous_test_new:: (833, 19)\n",
      "shape of X_test:: (833, 22)\n",
      "shape of X_train:: (17539, 22)\n",
      "shape of X_test:: (833, 22)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.6251830161 0.9976635514 0.7686768677       428\n",
      "           1  0.9933333333 0.3679012346 0.5369369369       405\n",
      "\n",
      "   micro avg  0.6914765906 0.6914765906 0.6914765906       833\n",
      "   macro avg  0.8092581747 0.6827823930 0.6528069023       833\n",
      "weighted avg  0.8041756673 0.6914765906 0.6560061931       833\n",
      "\n",
      "\n",
      "**************C is::1.050000*****************\n",
      "type of X_continuous_train_new:: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "shape of X_continuous_train_new:: (17539, 19)\n",
      "shape of X_train:: (17539, 22)\n",
      "type of X_continuous_test_new:: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "shape of X_continuous_test_new:: (833, 19)\n",
      "shape of X_test:: (833, 22)\n",
      "shape of X_train:: (17539, 22)\n",
      "shape of X_test:: (833, 22)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.6237188873 0.9976580796 0.7675675676       427\n",
      "           1  0.9933333333 0.3669950739 0.5359712230       406\n",
      "\n",
      "   micro avg  0.6902761104 0.6902761104 0.6902761104       833\n",
      "   macro avg  0.8085261103 0.6823265768 0.6517693953       833\n",
      "weighted avg  0.8038671047 0.6902761104 0.6546886769       833\n",
      "\n",
      "\n",
      "**************C is::1.100000*****************\n",
      "type of X_continuous_train_new:: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "shape of X_continuous_train_new:: (17539, 19)\n",
      "shape of X_train:: (17539, 22)\n",
      "type of X_continuous_test_new:: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "shape of X_continuous_test_new:: (833, 19)\n",
      "shape of X_test:: (833, 22)\n",
      "shape of X_train:: (17539, 22)\n",
      "shape of X_test:: (833, 22)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.6251830161 0.9976635514 0.7686768677       428\n",
      "           1  0.9933333333 0.3679012346 0.5369369369       405\n",
      "\n",
      "   micro avg  0.6914765906 0.6914765906 0.6914765906       833\n",
      "   macro avg  0.8092581747 0.6827823930 0.6528069023       833\n",
      "weighted avg  0.8041756673 0.6914765906 0.6560061931       833\n",
      "\n",
      "\n",
      "**************C is::1.150000*****************\n",
      "type of X_continuous_train_new:: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "shape of X_continuous_train_new:: (17539, 19)\n",
      "shape of X_train:: (17539, 22)\n",
      "type of X_continuous_test_new:: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "shape of X_continuous_test_new:: (833, 19)\n",
      "shape of X_test:: (833, 22)\n",
      "shape of X_train:: (17539, 22)\n",
      "shape of X_test:: (833, 22)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.6251830161 0.9976635514 0.7686768677       428\n",
      "           1  0.9933333333 0.3679012346 0.5369369369       405\n",
      "\n",
      "   micro avg  0.6914765906 0.6914765906 0.6914765906       833\n",
      "   macro avg  0.8092581747 0.6827823930 0.6528069023       833\n",
      "weighted avg  0.8041756673 0.6914765906 0.6560061931       833\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_SVC_l1(X_train, y_train, X_test, y_test,  C=0.01):\n",
    "    \n",
    "    # 归一化\n",
    "    ss = StandardScaler(with_mean=False)\n",
    "    X_continuous_train_new = ss.fit_transform(X_train[:, 0: -3])\n",
    "    print(\"type of X_continuous_train_new::\", type(X_continuous_train_new))\n",
    "    print(\"shape of X_continuous_train_new::\", X_continuous_train_new.shape)\n",
    "\n",
    "    # 将连续值和离散值拼接\n",
    "    X_train = np.hstack((X_continuous_train_new.A, X_train[:, -3:].A))   # .A转化为.numpy.ndarray\n",
    "    print(\"shape of X_train::\", X_train.shape)\n",
    "\n",
    "    # 归一化\n",
    "    X_continuous_test_new = ss.transform(X_test[:, 0: -3])\n",
    "    print(\"type of X_continuous_test_new::\", type(X_continuous_test_new))\n",
    "    print(\"shape of X_continuous_test_new::\", X_continuous_test_new.shape)\n",
    "\n",
    "    # 将连续值和离散值拼接\n",
    "    X_test = np.hstack((X_continuous_test_new.A, X_test[:, -3:].A))\n",
    "    print(\"shape of X_test::\", X_test.shape)\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    print(\"shape of X_train::\", X_train.shape)\n",
    "    print(\"shape of X_test::\", X_test.shape)\n",
    "    print(\"shape of y_train::\", y_train.shape)\n",
    "    print(\"Counter of y_train::\", Counter(y_train))\n",
    "    print(\"shape of y_test::\", y_test.shape)\n",
    "    print(\"Counter of y_test::\", Counter(y_test))\n",
    "    \n",
    "    xgbc = LinearSVC(C=C, penalty=\"l1\", dual=False)\n",
    "    xgbc.fit(X_train, y_train)\n",
    "    y_test_predict = xgbc.predict(X_test)\n",
    "    print(classification_report(y_test_predict, y_test, target_names=['0', '1'], digits=10))\n",
    "\n",
    "# 网格搜索\n",
    "\"\"\"\n",
    "连续特征共有19个，\n",
    "第一次网格搜索：range(0, 300, 30)，然后定位到：[1, 1.4];\n",
    "第二次网格搜索：range(100, 140, 10)，然后定位到：[1, 1.2];\n",
    "第三次网格搜索：range(100, 120, 5)，然后定位到：[1.1];\n",
    "\"\"\"\n",
    "for C in range(100, 120, 5):    \n",
    "    print()\n",
    "    param = C/100\n",
    "    X_train_copy = deepcopy(X_train)    \n",
    "    X_test_copy = deepcopy(X_test)\n",
    "    y_train_copy = deepcopy(y_train)\n",
    "    y_test_copy = deepcopy(y_test)\n",
    "    print(\"**************C is::%f*****************\" % param)\n",
    "    train_SVC_l1(X_train_copy, y_train_copy, X_test_copy, y_test_copy, param)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************C is::1.150000*****************\n",
      "type of X_continuous_train_new:: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "shape of X_continuous_train_new:: (17539, 19)\n",
      "shape of X_train:: (17539, 22)\n",
      "type of X_continuous_test_new:: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "shape of X_continuous_test_new:: (833, 19)\n",
      "shape of X_test:: (833, 22)\n",
      "shape of X_train:: (17539, 22)\n",
      "shape of X_test:: (833, 22)\n",
      "shape of y_train:: (17539,)\n",
      "Counter of y_train:: Counter({1: 16551, 0: 988})\n",
      "shape of y_test:: (833,)\n",
      "Counter of y_test:: Counter({0: 683, 1: 150})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.6251830161 0.9976635514 0.7686768677       428\n",
      "           1  0.9933333333 0.3679012346 0.5369369369       405\n",
      "\n",
      "   micro avg  0.6914765906 0.6914765906 0.6914765906       833\n",
      "   macro avg  0.8092581747 0.6827823930 0.6528069023       833\n",
      "weighted avg  0.8041756673 0.6914765906 0.6560061931       833\n",
      "\n",
      "type of X_continuous_test_all_new:: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "shape of X_continuous_test_all_new:: (181057, 19)\n",
      "shape of X_test_all:: (181057, 22)\n",
      "y_predict:: Counter({1: 181043, 0: 14})\n"
     ]
    }
   ],
   "source": [
    "# 通过上述网络搜索的结果，可以看出，到最后f1值的开始循环震荡，说明结果已经趋于稳定，我们只需要将C设置为1.55即可\n",
    "def train_and_test_SVC_L1_select(X_train, y_train, X_test, y_test,  X_test_all, C=1.1):\n",
    "    \n",
    "    # 归一化\n",
    "    ss = StandardScaler(with_mean=False)\n",
    "    X_continuous_train_new = ss.fit_transform(X_train[:, 0: -3])\n",
    "    print(\"type of X_continuous_train_new::\", type(X_continuous_train_new))\n",
    "    print(\"shape of X_continuous_train_new::\", X_continuous_train_new.shape)\n",
    "\n",
    "    # 将连续值和离散值拼接\n",
    "    X_train = np.hstack((X_continuous_train_new.A, X_train[:, -3:].A))   # .A转化为.numpy.ndarray\n",
    "    print(\"shape of X_train::\", X_train.shape)\n",
    "\n",
    "    # 归一化\n",
    "    X_continuous_test_new = ss.transform(X_test[:, 0: -3])\n",
    "    print(\"type of X_continuous_test_new::\", type(X_continuous_test_new))\n",
    "    print(\"shape of X_continuous_test_new::\", X_continuous_test_new.shape)\n",
    "\n",
    "    # 将连续值和离散值拼接\n",
    "    X_test = np.hstack((X_continuous_test_new.A, X_test[:, -3:].A))\n",
    "    print(\"shape of X_test::\", X_test.shape)\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    print(\"shape of X_train::\", X_train.shape)\n",
    "    print(\"shape of X_test::\", X_test.shape)\n",
    "    print(\"shape of y_train::\", y_train.shape)\n",
    "    print(\"Counter of y_train::\", Counter(y_train))\n",
    "    print(\"shape of y_test::\", y_test.shape)\n",
    "    print(\"Counter of y_test::\", Counter(y_test))\n",
    "    \n",
    "    xgbc = LinearSVC(C=C, penalty=\"l1\", dual=False)\n",
    "    xgbc.fit(X_train, y_train)\n",
    "    y_test_predict = xgbc.predict(X_test)\n",
    "    print(classification_report(y_test_predict, y_test, target_names=['0', '1'], digits=10))\n",
    "    \n",
    "    # 归一化\n",
    "    X_continuous_test_all_new = ss.transform(X_test_all[:, 0: -3])\n",
    "    print(\"type of X_continuous_test_all_new::\", type(X_continuous_test_all_new))\n",
    "    print(\"shape of X_continuous_test_all_new::\", X_continuous_test_all_new.shape)\n",
    "\n",
    "    # 将连续值和离散值拼接\n",
    "    X_test_all = np.hstack((X_continuous_test_all_new.A, X_test_all[:, -3:].A))\n",
    "    print(\"shape of X_test_all::\", X_test_all.shape)\n",
    "    \n",
    "    y_predict = xgbc.predict(X_test_all)\n",
    "    print(\"y_predict::\", Counter(y_predict))\n",
    "\n",
    "X_train_copy = deepcopy(X_train)    \n",
    "X_test_copy = deepcopy(X_test)\n",
    "y_train_copy = deepcopy(y_train)\n",
    "y_test_copy = deepcopy(y_test)\n",
    "X_test_all = deepcopy(X_test_all)\n",
    "print(\"**************C is::%f*****************\" % param)\n",
    "train_and_test_SVC_L1_select(X_train_copy, y_train_copy, X_test_copy, y_test_copy, X_test_all)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分析：\n",
    "\n",
    "本代码说明，在所有的特征选择方法中，针对此数据集，效果最好的是使用方差分析的情况，但是仔细观察可以发现，使用方差分析的时候是保留全部特征的，这说明，对于比较小的数据集而言，可以不进行特征选择。但是即使是最好的情况，效果也不是很好，所以仍然需要采用其他的办法提高性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
