{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 功能\n",
    "\n",
    "在有标签数据集中，正例数目17000左右，负例数目1709个，所以存在严重的不平衡问题，所以我们尝试解决这个问题。\n",
    "\n",
    "为了解决这个问题，我们需要处理不平衡数据，本py文件使用的是过采样的方法，使用的SMOTE，RandomOverSampler和ADASYN。\n",
    "\n",
    "特征选择使用的是RFECV（由featureSelectionBasic.ipynb得到）\n",
    "\n",
    "参考文章：https://beckernick.github.io/oversampling-modeling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "from imblearn.over_sampling import SMOTE,ADASYN,RandomOverSampler\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connection = pymysql.Connect(\n",
    "    host=\"localhost\",\n",
    "    port=3306,\n",
    "    user=\"root\",\n",
    "    passwd=\"root\",\n",
    "    charset=\"utf8\",\n",
    "    db=\"project_researchers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data: (18694, 21)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18694 entries, 0 to 18693\n",
      "Data columns (total 21 columns):\n",
      "bys_cn                18442 non-null float64\n",
      "hindex_cn             18557 non-null float64\n",
      "a_paper               18694 non-null int64\n",
      "b_paper               18694 non-null int64\n",
      "c_paper               18694 non-null int64\n",
      "papernum2017          18694 non-null int64\n",
      "papernum2016          18694 non-null int64\n",
      "papernum2015          18694 non-null int64\n",
      "papernum2014          18694 non-null int64\n",
      "papernum2013          18694 non-null int64\n",
      "num_journal           18694 non-null int64\n",
      "num_conference        18694 non-null int64\n",
      "degree                18623 non-null float64\n",
      "pagerank              18623 non-null float64\n",
      "degree_centrality     18623 non-null float64\n",
      "diff_year             18623 non-null float64\n",
      "coauthors_top10000    18694 non-null int64\n",
      "coauthors_top20000    18694 non-null int64\n",
      "coauthors_top30000    18694 non-null int64\n",
      "category              18694 non-null int64\n",
      "label                 18694 non-null int64\n",
      "dtypes: float64(6), int64(15)\n",
      "memory usage: 3.0 MB\n",
      "data.info(): None\n"
     ]
    }
   ],
   "source": [
    "def getData(connection):\n",
    "    \"\"\"\n",
    "    查询数据，包括特征和标签\n",
    "    :param connection:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    sql_select = \"\"\"\n",
    "    SELECT bys_cn, hindex_cn,a_conf+a_journal as a_paper, b_conf + b_journal as b_paper,c_conf + c_journal as c_paper,papernum2017, papernum2016, papernum2015, papernum2014, papernum2013,num_journal,num_conference, project_num, degree, pagerank,degree_centrality,last_year - first_year as diff_year , coauthors_top10000, coauthors_top20000, coauthors_top30000, category, label \n",
    "    FROM classifier_isTeacher_xgbc WHERE (label =1 or label = 0) and category is not null\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(sql_select, connection)\n",
    "    all_features = ['bys_cn', 'hindex_cn', 'a_paper', 'b_paper', 'c_paper', 'papernum2017', 'papernum2016', 'papernum2015', 'papernum2014', 'papernum2013', 'num_journal', 'num_conference',  'degree', 'pagerank', 'degree_centrality', 'diff_year', 'coauthors_top10000', 'coauthors_top20000', 'coauthors_top30000', 'category', 'label']\n",
    "    data = df[all_features]\n",
    "    return data\n",
    "\n",
    "data = getData(connection)\n",
    "print(\"shape of data:\", data.shape)\n",
    "print(\"data.info():\", data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data:: (18372, 21)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18372 entries, 0 to 18692\n",
      "Data columns (total 21 columns):\n",
      "bys_cn                18372 non-null float64\n",
      "hindex_cn             18372 non-null float64\n",
      "a_paper               18372 non-null int64\n",
      "b_paper               18372 non-null int64\n",
      "c_paper               18372 non-null int64\n",
      "papernum2017          18372 non-null int64\n",
      "papernum2016          18372 non-null int64\n",
      "papernum2015          18372 non-null int64\n",
      "papernum2014          18372 non-null int64\n",
      "papernum2013          18372 non-null int64\n",
      "num_journal           18372 non-null int64\n",
      "num_conference        18372 non-null int64\n",
      "degree                18372 non-null float64\n",
      "pagerank              18372 non-null float64\n",
      "degree_centrality     18372 non-null float64\n",
      "diff_year             18372 non-null float64\n",
      "coauthors_top10000    18372 non-null int64\n",
      "coauthors_top20000    18372 non-null int64\n",
      "coauthors_top30000    18372 non-null int64\n",
      "category              18372 non-null int64\n",
      "label                 18372 non-null int64\n",
      "dtypes: float64(6), int64(15)\n",
      "memory usage: 3.1 MB\n",
      "data.info():: None\n"
     ]
    }
   ],
   "source": [
    "# 对缺失值进行处理\n",
    "# Method1：直接将含有缺失字段的值去掉\n",
    "data = data.dropna()\n",
    "print(\"shape of data::\", data.shape)\n",
    "print(\"data.info()::\", data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18372 entries, 0 to 18692\n",
      "Data columns (total 19 columns):\n",
      "bys_cn                18372 non-null float64\n",
      "hindex_cn             18372 non-null float64\n",
      "a_paper               18372 non-null int64\n",
      "b_paper               18372 non-null int64\n",
      "c_paper               18372 non-null int64\n",
      "papernum2017          18372 non-null int64\n",
      "papernum2016          18372 non-null int64\n",
      "papernum2015          18372 non-null int64\n",
      "papernum2014          18372 non-null int64\n",
      "papernum2013          18372 non-null int64\n",
      "num_journal           18372 non-null int64\n",
      "num_conference        18372 non-null int64\n",
      "degree                18372 non-null float64\n",
      "pagerank              18372 non-null float64\n",
      "degree_centrality     18372 non-null float64\n",
      "diff_year             18372 non-null float64\n",
      "coauthors_top10000    18372 non-null int64\n",
      "coauthors_top20000    18372 non-null int64\n",
      "coauthors_top30000    18372 non-null int64\n",
      "dtypes: float64(6), int64(13)\n",
      "memory usage: 2.8 MB\n",
      "info of X_continuous:: None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18372 entries, 0 to 18692\n",
      "Data columns (total 1 columns):\n",
      "category    18372 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 287.1 KB\n",
      "info of X_discrete:: None\n",
      "y:: Counter({1: 16701, 0: 1671})\n"
     ]
    }
   ],
   "source": [
    "# 将连续值和离散值以及y分开\n",
    "continuous_features = ['bys_cn', 'hindex_cn', 'a_paper', 'b_paper', 'c_paper', 'papernum2017', 'papernum2016', 'papernum2015', 'papernum2014', 'papernum2013', 'num_journal', 'num_conference',  'degree', 'pagerank', 'degree_centrality', 'diff_year', 'coauthors_top10000', 'coauthors_top20000', 'coauthors_top30000']\n",
    "discrete_features = ['category']\n",
    "X_continous = data[continuous_features]\n",
    "X_discrete = data[discrete_features]\n",
    "y = data['label']\n",
    "print(\"info of X_continuous::\", X_continous.info())\n",
    "print(\"info of X_discrete::\", X_discrete.info())\n",
    "print(\"y::\", Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "shape of X_all:: (18372, 22)\n"
     ]
    }
   ],
   "source": [
    "# 将离散值变成one-hot编码\n",
    "X_discrete_oneHot = OneHotEncoder(sparse=False).fit_transform(X_discrete)\n",
    "print(X_discrete_oneHot)\n",
    "\n",
    "X_all = np.hstack((X_continous, X_discrete_oneHot))\n",
    "print(\"shape of X_all::\", X_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、获取需要预测的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data_test: (181057, 20)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 181057 entries, 0 to 181056\n",
      "Data columns (total 20 columns):\n",
      "bys_cn                176811 non-null float64\n",
      "hindex_cn             180624 non-null float64\n",
      "a_paper               181057 non-null int64\n",
      "b_paper               181057 non-null int64\n",
      "c_paper               181057 non-null int64\n",
      "papernum2017          181057 non-null int64\n",
      "papernum2016          181057 non-null int64\n",
      "papernum2015          181057 non-null int64\n",
      "papernum2014          181057 non-null int64\n",
      "papernum2013          181057 non-null int64\n",
      "num_journal           181057 non-null int64\n",
      "num_conference        181057 non-null int64\n",
      "degree                180847 non-null float64\n",
      "pagerank              180847 non-null float64\n",
      "degree_centrality     180847 non-null float64\n",
      "diff_year             180847 non-null float64\n",
      "coauthors_top10000    181057 non-null int64\n",
      "coauthors_top20000    181057 non-null int64\n",
      "coauthors_top30000    181057 non-null int64\n",
      "category              181057 non-null int64\n",
      "dtypes: float64(6), int64(14)\n",
      "memory usage: 27.6 MB\n",
      "data_test.info(): None\n"
     ]
    }
   ],
   "source": [
    "def getPredictData(connection):\n",
    "    \"\"\"\n",
    "    获取需要预测的数据，包括训练集中的特征\n",
    "    :param connection:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    sql_select = \"\"\"\n",
    "    SELECT bys_cn, hindex_cn,a_conf+a_journal as a_paper, b_conf + b_journal as b_paper,c_conf + c_journal as c_paper,papernum2017, papernum2016, papernum2015, papernum2014, papernum2013,num_journal,num_conference, project_num, degree, pagerank,degree_centrality,last_year - first_year as diff_year , coauthors_top10000, coauthors_top20000, coauthors_top30000, category \n",
    "    FROM classifier_isTeacher_xgbc WHERE label is null and category is not null\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(sql_select, connection)\n",
    "    all_features = ['bys_cn', 'hindex_cn', 'a_paper', 'b_paper', 'c_paper', 'papernum2017', 'papernum2016', 'papernum2015', 'papernum2014', 'papernum2013', 'num_journal', 'num_conference',  'degree', 'pagerank', 'degree_centrality', 'diff_year', 'coauthors_top10000', 'coauthors_top20000', 'coauthors_top30000', 'category']\n",
    "    data = df[all_features]\n",
    "    return data\n",
    "\n",
    "data_test = getPredictData(connection)\n",
    "print(\"shape of data_test:\", data_test.shape)\n",
    "print(\"data_test.info():\", data_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、处理predictData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 181057 entries, 0 to 181056\n",
      "Data columns (total 20 columns):\n",
      "bys_cn                181057 non-null float64\n",
      "hindex_cn             181057 non-null float64\n",
      "a_paper               181057 non-null int64\n",
      "b_paper               181057 non-null int64\n",
      "c_paper               181057 non-null int64\n",
      "papernum2017          181057 non-null int64\n",
      "papernum2016          181057 non-null int64\n",
      "papernum2015          181057 non-null int64\n",
      "papernum2014          181057 non-null int64\n",
      "papernum2013          181057 non-null int64\n",
      "num_journal           181057 non-null int64\n",
      "num_conference        181057 non-null int64\n",
      "degree                181057 non-null float64\n",
      "pagerank              181057 non-null float64\n",
      "degree_centrality     181057 non-null float64\n",
      "diff_year             181057 non-null float64\n",
      "coauthors_top10000    181057 non-null int64\n",
      "coauthors_top20000    181057 non-null int64\n",
      "coauthors_top30000    181057 non-null int64\n",
      "category              181057 non-null int64\n",
      "dtypes: float64(6), int64(14)\n",
      "memory usage: 27.6 MB\n",
      "info of data_test_fill:: None\n",
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n",
      "shape of X_test_all:: (181057, 22)\n"
     ]
    }
   ],
   "source": [
    "# 使用0进行填充\n",
    "data_test_fill = data_test.fillna(0)\n",
    "print(\"info of data_test_fill::\", data_test_fill.info())\n",
    "\n",
    "# 将连续特征和离散特征区分开\n",
    "X_test_continous = data_test_fill[continuous_features]\n",
    "X_test_discrete = data_test_fill[discrete_features]\n",
    "\n",
    "# 离散特征使用one-hot编码\n",
    "X_test_discrete_oneHot = OneHotEncoder(sparse=False).fit_transform(X_test_discrete)\n",
    "print(X_test_discrete_oneHot)\n",
    "\n",
    "X_test_all = np.hstack((X_test_continous, X_test_discrete_oneHot))\n",
    "print(\"shape of X_test_all::\", X_test_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5、使用SMOTE方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features::15\n",
      "Ranking of features:: [1 1 3 4 1 1 1 2 1 6 1 1 1 1 7 1 5 1 1 1 8 1]\n",
      "selector.support_:: [ True  True False False  True  True  True False  True False  True  True\n",
      "  True  True False  True False  True  True  True False  True]\n",
      "type of X_continuous_new:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_new:: (18372, 14)\n",
      "type of X_test_continous_new:: <class 'numpy.ndarray'>\n",
      "shape of X_test_continous_new:: (181057, 14)\n",
      "shape of X_all:: (18372, 22)\n",
      "shape of X_test_all:: (181057, 22)\n",
      "shape of X_train:: (14697, 15)\n",
      "shape of X_test:: (3675, 15)\n",
      "shape of y_train:: (14697,)\n",
      "Counter of y_train:: Counter({1: 13387, 0: 1310})\n",
      "shape of y_test:: (3675,)\n",
      "Counter of y_test:: Counter({1: 3314, 0: 361})\n",
      "shape of X_train_res:: (26774, 15)\n",
      "shape of y_train_res:: (26774,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.91136   0.66870   0.77140       492\n",
      "           0    0.95081   0.98995   0.96999      3183\n",
      "\n",
      "   micro avg    0.94694   0.94694   0.94694      3675\n",
      "   macro avg    0.93109   0.82932   0.87069      3675\n",
      "weighted avg    0.94553   0.94694   0.94340      3675\n",
      "\n",
      "y_predict:: Counter({0: 97515, 1: 83542})\n"
     ]
    }
   ],
   "source": [
    "# 通过观察可以发现，使用rfe方法，当n_features_to_select=15时，f1值可以达到最大值：0.96038，这也是方差分析，rfe和rfecv中最好的效果。\n",
    "def trainAndTestXGBCrfeSMOTE(X_all, y, X_test_all, n_features_to_select=15):\n",
    "    \n",
    "     # RFECV\n",
    "    estimator = XGBClassifier()\n",
    "    selector = RFE(estimator=estimator, n_features_to_select = n_features_to_select)\n",
    "    X_all_rfe = selector.fit_transform(X_all, y) \n",
    "    print(\"Optimal number of features::%d\" % selector.n_features_)\n",
    "    print(\"Ranking of features:: %s\" % selector.ranking_)\n",
    "    X_test_all_rfe = selector.transform(X_test_all)\n",
    "    selected_idx = np.where(pd.Series(selector.support_)==True)[0]   # n_features_to_select个选择出来的特征，每一个特征为True\n",
    "    print(\"selector.support_::\", selector.support_)\n",
    "    \n",
    "    # 因为Wrapper离散特征和连续特征需要一起训练搜索特征子集，但是因为离散特征不需要标准化，所以这里需要将其分开\n",
    "    discrete_idx = list(set([19, 20, 21]) - set(selected_idx))   # 最后3列为离散值\n",
    "    X_continuous_tmp = pd.DataFrame(X_all_rfe)[list(range(0, len(selected_idx)-len(discrete_idx)))]\n",
    "    X_discreate_tmp = pd.DataFrame(X_all_rfe)[list(range(len(selected_idx)-len(discrete_idx), len(selected_idx)))]\n",
    "    X_test_continuous_tmp = pd.DataFrame(X_test_all_rfe)[list(range(0, len(selected_idx)-len(discrete_idx)))]\n",
    "    X_test_discreate_tmp = pd.DataFrame(X_test_all_rfe)[list(range(len(selected_idx)-len(discrete_idx), len(selected_idx)))]\n",
    "    \n",
    "    # 归一化\n",
    "    ss = StandardScaler()\n",
    "    X_continuous_new = ss.fit_transform(X_continuous_tmp)\n",
    "    print(\"type of X_continuous_new::\", type(X_continuous_new))\n",
    "    print(\"shape of X_continuous_new::\", X_continuous_new.shape)\n",
    "    X_test_continous_new = ss.transform(X_test_continuous_tmp)\n",
    "    print(\"type of X_test_continous_new::\", type(X_test_continous_new))\n",
    "    print(\"shape of X_test_continous_new::\", X_test_continous_new.shape)\n",
    "\n",
    "    # 将连续值和离散值拼接\n",
    "    X_all_new = np.hstack((X_continuous_new, X_discreate_tmp))\n",
    "    print(\"shape of X_all::\", X_all.shape)\n",
    "    X_test_all_new = np.hstack((X_test_continous_new, X_test_discreate_tmp))\n",
    "    print(\"shape of X_test_all::\", X_test_all.shape)\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_all_new, y, test_size=0.2, random_state=33)\n",
    "    \n",
    "    print(\"shape of X_train::\", X_train.shape)\n",
    "    print(\"shape of X_test::\", X_test.shape)\n",
    "    print(\"shape of y_train::\", y_train.shape)\n",
    "    print(\"Counter of y_train::\", Counter(y_train))\n",
    "    print(\"shape of y_test::\", y_test.shape)\n",
    "    print(\"Counter of y_test::\", Counter(y_test))\n",
    "    \n",
    "    sm = SMOTE(random_state=12, ratio=1.0)\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "    print(\"shape of X_train_res::\", X_train_res.shape)\n",
    "    print(\"shape of y_train_res::\", y_train_res.shape)\n",
    "    \n",
    "    \n",
    "    xgbc = XGBClassifier()\n",
    "    xgbc.fit(X_train_res, y_train_res)\n",
    "    y_test_predict = xgbc.predict(X_test)\n",
    "    print(classification_report(y_test_predict, y_test, target_names=['1', '0'], digits=5))\n",
    "    \n",
    "    y_predict = xgbc.predict(X_test_all_new)\n",
    "    print(\"y_predict::\", Counter(y_predict))\n",
    "\n",
    "# 调用预测函数\n",
    "X_all_copy = X_all.copy()\n",
    "y_copy = y.copy()\n",
    "X_test_all_copy = X_test_all.copy()\n",
    "trainAndTestXGBCrfeSMOTE(X_all_copy, y_copy, X_test_all_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6、使用ADASYN方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features::15\n",
      "Ranking of features:: [1 1 3 4 1 1 1 2 1 6 1 1 1 1 7 1 5 1 1 1 8 1]\n",
      "selector.support_:: [ True  True False False  True  True  True False  True False  True  True\n",
      "  True  True False  True False  True  True  True False  True]\n",
      "type of X_continuous_new:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_new:: (18372, 14)\n",
      "type of X_test_continous_new:: <class 'numpy.ndarray'>\n",
      "shape of X_test_continous_new:: (181057, 14)\n",
      "shape of X_all:: (18372, 22)\n",
      "shape of X_test_all:: (181057, 22)\n",
      "shape of X_train:: (14697, 15)\n",
      "shape of X_test:: (3675, 15)\n",
      "shape of y_train:: (14697,)\n",
      "Counter of y_train:: Counter({1: 13387, 0: 1310})\n",
      "shape of y_test:: (3675,)\n",
      "Counter of y_test:: Counter({1: 3314, 0: 361})\n",
      "shape of X_train_res:: (26692, 15)\n",
      "shape of y_train_res:: (26692,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.93352   0.60394   0.73341       558\n",
      "           0    0.93331   0.99230   0.96190      3117\n",
      "\n",
      "   micro avg    0.93333   0.93333   0.93333      3675\n",
      "   macro avg    0.93342   0.79812   0.84765      3675\n",
      "weighted avg    0.93334   0.93333   0.92721      3675\n",
      "\n",
      "y_predict:: Counter({0: 108683, 1: 72374})\n"
     ]
    }
   ],
   "source": [
    "# 通过观察可以发现，使用rfe方法，当n_features_to_select=15时，f1值可以达到最大值：0.96038，这也是方差分析，rfe和rfecv中最好的效果。\n",
    "def trainAndTestXGBCrfeADASYN(X_all, y, X_test_all, n_features_to_select=15):\n",
    "    \n",
    "     # RFECV\n",
    "    estimator = XGBClassifier()\n",
    "    selector = RFE(estimator=estimator, n_features_to_select = n_features_to_select)\n",
    "    X_all_rfe = selector.fit_transform(X_all, y) \n",
    "    print(\"Optimal number of features::%d\" % selector.n_features_)\n",
    "    print(\"Ranking of features:: %s\" % selector.ranking_)\n",
    "    X_test_all_rfe = selector.transform(X_test_all)\n",
    "    selected_idx = np.where(pd.Series(selector.support_)==True)[0]   # n_features_to_select个选择出来的特征，每一个特征为True\n",
    "    print(\"selector.support_::\", selector.support_)\n",
    "    \n",
    "    # 因为Wrapper离散特征和连续特征需要一起训练搜索特征子集，但是因为离散特征不需要标准化，所以这里需要将其分开\n",
    "    discrete_idx = list(set([19, 20, 21]) - set(selected_idx))   # 最后3列为离散值\n",
    "    X_continuous_tmp = pd.DataFrame(X_all_rfe)[list(range(0, len(selected_idx)-len(discrete_idx)))]\n",
    "    X_discreate_tmp = pd.DataFrame(X_all_rfe)[list(range(len(selected_idx)-len(discrete_idx), len(selected_idx)))]\n",
    "    X_test_continuous_tmp = pd.DataFrame(X_test_all_rfe)[list(range(0, len(selected_idx)-len(discrete_idx)))]\n",
    "    X_test_discreate_tmp = pd.DataFrame(X_test_all_rfe)[list(range(len(selected_idx)-len(discrete_idx), len(selected_idx)))]\n",
    "    \n",
    "    # 归一化\n",
    "    ss = StandardScaler()\n",
    "    X_continuous_new = ss.fit_transform(X_continuous_tmp)\n",
    "    print(\"type of X_continuous_new::\", type(X_continuous_new))\n",
    "    print(\"shape of X_continuous_new::\", X_continuous_new.shape)\n",
    "    X_test_continous_new = ss.transform(X_test_continuous_tmp)\n",
    "    print(\"type of X_test_continous_new::\", type(X_test_continous_new))\n",
    "    print(\"shape of X_test_continous_new::\", X_test_continous_new.shape)\n",
    "\n",
    "    # 将连续值和离散值拼接\n",
    "    X_all_new = np.hstack((X_continuous_new, X_discreate_tmp))\n",
    "    print(\"shape of X_all::\", X_all.shape)\n",
    "    X_test_all_new = np.hstack((X_test_continous_new, X_test_discreate_tmp))\n",
    "    print(\"shape of X_test_all::\", X_test_all.shape)\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_all_new, y, test_size=0.2, random_state=33)\n",
    "    \n",
    "    print(\"shape of X_train::\", X_train.shape)\n",
    "    print(\"shape of X_test::\", X_test.shape)\n",
    "    print(\"shape of y_train::\", y_train.shape)\n",
    "    print(\"Counter of y_train::\", Counter(y_train))\n",
    "    print(\"shape of y_test::\", y_test.shape)\n",
    "    print(\"Counter of y_test::\", Counter(y_test))\n",
    "    \n",
    "    sm = ADASYN(random_state=12, ratio=1.0)\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "    print(\"shape of X_train_res::\", X_train_res.shape)\n",
    "    print(\"shape of y_train_res::\", y_train_res.shape)\n",
    "    \n",
    "    \n",
    "    xgbc = XGBClassifier()\n",
    "    xgbc.fit(X_train_res, y_train_res)\n",
    "    y_test_predict = xgbc.predict(X_test)\n",
    "    print(classification_report(y_test_predict, y_test, target_names=['1', '0'], digits=5))\n",
    "    \n",
    "    y_predict = xgbc.predict(X_test_all_new)\n",
    "    print(\"y_predict::\", Counter(y_predict))\n",
    "\n",
    "# 调用预测函数\n",
    "X_all_copy = X_all.copy()\n",
    "y_copy = y.copy()\n",
    "X_test_all_copy = X_test_all.copy()\n",
    "trainAndTestXGBCrfeADASYN(X_all_copy, y_copy, X_test_all_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7、使用随机上采样方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features::15\n",
      "Ranking of features:: [1 1 3 4 1 1 1 2 1 6 1 1 1 1 7 1 5 1 1 1 8 1]\n",
      "selector.support_:: [ True  True False False  True  True  True False  True False  True  True\n",
      "  True  True False  True False  True  True  True False  True]\n",
      "type of X_continuous_new:: <class 'numpy.ndarray'>\n",
      "shape of X_continuous_new:: (18372, 14)\n",
      "type of X_test_continous_new:: <class 'numpy.ndarray'>\n",
      "shape of X_test_continous_new:: (181057, 14)\n",
      "shape of X_all:: (18372, 22)\n",
      "shape of X_test_all:: (181057, 22)\n",
      "shape of X_train:: (14697, 15)\n",
      "shape of X_test:: (3675, 15)\n",
      "shape of y_train:: (14697,)\n",
      "Counter of y_train:: Counter({1: 13387, 0: 1310})\n",
      "shape of y_test:: (3675,)\n",
      "Counter of y_test:: Counter({1: 3314, 0: 361})\n",
      "shape of X_train_res:: (26774, 15)\n",
      "shape of y_train_res:: (26774,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.95845   0.57475   0.71859       602\n",
      "           0    0.92275   0.99512   0.95757      3073\n",
      "\n",
      "   micro avg    0.92626   0.92626   0.92626      3675\n",
      "   macro avg    0.94060   0.78493   0.83808      3675\n",
      "weighted avg    0.92860   0.92626   0.91842      3675\n",
      "\n",
      "y_predict:: Counter({0: 112803, 1: 68254})\n"
     ]
    }
   ],
   "source": [
    "# 通过观察可以发现，使用rfe方法，当n_features_to_select=15时，f1值可以达到最大值：0.96038，这也是方差分析，rfe和rfecv中最好的效果。\n",
    "def trainAndTestXGBCrfeROS(X_all, y, X_test_all, n_features_to_select=15):\n",
    "    \n",
    "     # RFECV\n",
    "    estimator = XGBClassifier()\n",
    "    selector = RFE(estimator=estimator, n_features_to_select=n_features_to_select)\n",
    "    X_all_rfe = selector.fit_transform(X_all, y) \n",
    "    print(\"Optimal number of features::%d\" % selector.n_features_)\n",
    "    print(\"Ranking of features:: %s\" % selector.ranking_)\n",
    "    X_test_all_rfe = selector.transform(X_test_all)\n",
    "    selected_idx = np.where(pd.Series(selector.support_)==True)[0]   # n_features_to_select个选择出来的特征，每一个特征为True\n",
    "    print(\"selector.support_::\", selector.support_)\n",
    "    \n",
    "    # 因为Wrapper离散特征和连续特征需要一起训练搜索特征子集，但是因为离散特征不需要标准化，所以这里需要将其分开\n",
    "    discrete_idx = list(set([19, 20, 21]) - set(selected_idx))   # 最后3列为离散值\n",
    "    X_continuous_tmp = pd.DataFrame(X_all_rfe)[list(range(0, len(selected_idx)-len(discrete_idx)))]\n",
    "    X_discreate_tmp = pd.DataFrame(X_all_rfe)[list(range(len(selected_idx)-len(discrete_idx), len(selected_idx)))]\n",
    "    X_test_continuous_tmp = pd.DataFrame(X_test_all_rfe)[list(range(0, len(selected_idx)-len(discrete_idx)))]\n",
    "    X_test_discreate_tmp = pd.DataFrame(X_test_all_rfe)[list(range(len(selected_idx)-len(discrete_idx), len(selected_idx)))]\n",
    "    \n",
    "    # 归一化\n",
    "    ss = StandardScaler()\n",
    "    X_continuous_new = ss.fit_transform(X_continuous_tmp)\n",
    "    print(\"type of X_continuous_new::\", type(X_continuous_new))\n",
    "    print(\"shape of X_continuous_new::\", X_continuous_new.shape)\n",
    "    X_test_continous_new = ss.transform(X_test_continuous_tmp)\n",
    "    print(\"type of X_test_continous_new::\", type(X_test_continous_new))\n",
    "    print(\"shape of X_test_continous_new::\", X_test_continous_new.shape)\n",
    "\n",
    "    # 将连续值和离散值拼接\n",
    "    X_all_new = np.hstack((X_continuous_new, X_discreate_tmp))\n",
    "    print(\"shape of X_all::\", X_all.shape)\n",
    "    X_test_all_new = np.hstack((X_test_continous_new, X_test_discreate_tmp))\n",
    "    print(\"shape of X_test_all::\", X_test_all.shape)\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_all_new, y, test_size=0.2, random_state=33)\n",
    "    \n",
    "    print(\"shape of X_train::\", X_train.shape)\n",
    "    print(\"shape of X_test::\", X_test.shape)\n",
    "    print(\"shape of y_train::\", y_train.shape)\n",
    "    print(\"Counter of y_train::\", Counter(y_train))\n",
    "    print(\"shape of y_test::\", y_test.shape)\n",
    "    print(\"Counter of y_test::\", Counter(y_test))\n",
    "    \n",
    "    sm = RandomOverSampler(random_state=12, ratio=1.0)\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "    print(\"shape of X_train_res::\", X_train_res.shape)\n",
    "    print(\"shape of y_train_res::\", y_train_res.shape)\n",
    "    \n",
    "    \n",
    "    xgbc = XGBClassifier()\n",
    "    xgbc.fit(X_train_res, y_train_res)\n",
    "    y_test_predict = xgbc.predict(X_test)\n",
    "    print(classification_report(y_test_predict, y_test, target_names=['1', '0'], digits=5))\n",
    "    \n",
    "    y_predict = xgbc.predict(X_test_all_new)\n",
    "    print(\"y_predict::\", Counter(y_predict))\n",
    "\n",
    "# 调用预测函数\n",
    "X_all_copy = X_all.copy()\n",
    "y_copy = y.copy()\n",
    "X_test_all_copy = X_test_all.copy()\n",
    "trainAndTestXGBCrfeROS(X_all_copy, y_copy, X_test_all_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
