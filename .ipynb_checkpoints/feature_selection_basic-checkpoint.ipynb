{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 内容简介\n",
    "\n",
    "特征选择的常用方法，包括Filter、Wrapper和Embedded方法。\n",
    "\n",
    "Filter方法包括方差分析、相关系数法、卡方检验、F检验和互信息法。\n",
    "\n",
    "Wrapper主要是递归特征消除法。\n",
    "\n",
    "Embedded方法主要包括基于树模型的特征选择法和基于正则化的特征选择法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from scipy.stats import pearsonr\n",
    "from collections import Counter\n",
    "from sklearn.feature_selection import chi2   # 卡方检验\n",
    "from sklearn.feature_selection import SelectKBest   # 根据 k个最高分选择功能。\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import f_classif   # F检验\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.Connect(\n",
    "    host=\"localhost\",\n",
    "    port=3306,\n",
    "    user=\"root\",\n",
    "    passwd=\"root\",\n",
    "    charset=\"utf8\",\n",
    "    db=\"project_researchers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data: (18694, 21)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18694 entries, 0 to 18693\n",
      "Data columns (total 21 columns):\n",
      "bys_cn                18442 non-null float64\n",
      "hindex_cn             18557 non-null float64\n",
      "a_paper               18694 non-null int64\n",
      "b_paper               18694 non-null int64\n",
      "c_paper               18694 non-null int64\n",
      "papernum2017          18694 non-null int64\n",
      "papernum2016          18694 non-null int64\n",
      "papernum2015          18694 non-null int64\n",
      "papernum2014          18694 non-null int64\n",
      "papernum2013          18694 non-null int64\n",
      "num_journal           18694 non-null int64\n",
      "num_conference        18694 non-null int64\n",
      "degree                18623 non-null float64\n",
      "pagerank              18623 non-null float64\n",
      "degree_centrality     18623 non-null float64\n",
      "diff_year             18623 non-null float64\n",
      "coauthors_top10000    18694 non-null int64\n",
      "coauthors_top20000    18694 non-null int64\n",
      "coauthors_top30000    18694 non-null int64\n",
      "category              18694 non-null int64\n",
      "label                 18694 non-null int64\n",
      "dtypes: float64(6), int64(15)\n",
      "memory usage: 3.0 MB\n",
      "data.info(): None\n"
     ]
    }
   ],
   "source": [
    "def get_data(connection):\n",
    "    \"\"\"\n",
    "    查询数据，包括特征和标签\n",
    "    :param connection:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    sql_select = \"\"\"\n",
    "    SELECT bys_cn, hindex_cn,a_conf+a_journal as a_paper, b_conf + b_journal as b_paper,c_conf + c_journal as c_paper,papernum2017, papernum2016, papernum2015, papernum2014, papernum2013,num_journal,num_conference, project_num, degree, pagerank,degree_centrality,last_year - first_year as diff_year , coauthors_top10000, coauthors_top20000, coauthors_top30000, category, label \n",
    "    FROM classifier_isTeacher_label WHERE (label =1 or label = 0) and category is not null\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(sql_select, connection)\n",
    "    all_features = ['bys_cn', 'hindex_cn', 'a_paper', 'b_paper', 'c_paper', 'papernum2017', 'papernum2016', 'papernum2015', 'papernum2014', 'papernum2013', 'num_journal', 'num_conference',  'degree', 'pagerank', 'degree_centrality', 'diff_year', 'coauthors_top10000', 'coauthors_top20000', 'coauthors_top30000', 'category', 'label']\n",
    "    data = df[all_features]\n",
    "    return data\n",
    "\n",
    "data = get_data(connection)\n",
    "print(\"shape of data:\", data.shape)\n",
    "print(\"data.info():\", data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data:: (18372, 21)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18372 entries, 0 to 18692\n",
      "Data columns (total 21 columns):\n",
      "bys_cn                18372 non-null float64\n",
      "hindex_cn             18372 non-null float64\n",
      "a_paper               18372 non-null int64\n",
      "b_paper               18372 non-null int64\n",
      "c_paper               18372 non-null int64\n",
      "papernum2017          18372 non-null int64\n",
      "papernum2016          18372 non-null int64\n",
      "papernum2015          18372 non-null int64\n",
      "papernum2014          18372 non-null int64\n",
      "papernum2013          18372 non-null int64\n",
      "num_journal           18372 non-null int64\n",
      "num_conference        18372 non-null int64\n",
      "degree                18372 non-null float64\n",
      "pagerank              18372 non-null float64\n",
      "degree_centrality     18372 non-null float64\n",
      "diff_year             18372 non-null float64\n",
      "coauthors_top10000    18372 non-null int64\n",
      "coauthors_top20000    18372 non-null int64\n",
      "coauthors_top30000    18372 non-null int64\n",
      "category              18372 non-null int64\n",
      "label                 18372 non-null int64\n",
      "dtypes: float64(6), int64(15)\n",
      "memory usage: 3.1 MB\n",
      "data.info():: None\n"
     ]
    }
   ],
   "source": [
    "# 对缺失值进行处理\n",
    "# Method1：直接将含有缺失字段的值去掉\n",
    "data = data.dropna()\n",
    "print(\"shape of data::\", data.shape)\n",
    "print(\"data.info()::\", data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18372 entries, 0 to 18692\n",
      "Data columns (total 19 columns):\n",
      "bys_cn                18372 non-null float64\n",
      "hindex_cn             18372 non-null float64\n",
      "a_paper               18372 non-null int64\n",
      "b_paper               18372 non-null int64\n",
      "c_paper               18372 non-null int64\n",
      "papernum2017          18372 non-null int64\n",
      "papernum2016          18372 non-null int64\n",
      "papernum2015          18372 non-null int64\n",
      "papernum2014          18372 non-null int64\n",
      "papernum2013          18372 non-null int64\n",
      "num_journal           18372 non-null int64\n",
      "num_conference        18372 non-null int64\n",
      "degree                18372 non-null float64\n",
      "pagerank              18372 non-null float64\n",
      "degree_centrality     18372 non-null float64\n",
      "diff_year             18372 non-null float64\n",
      "coauthors_top10000    18372 non-null int64\n",
      "coauthors_top20000    18372 non-null int64\n",
      "coauthors_top30000    18372 non-null int64\n",
      "dtypes: float64(6), int64(13)\n",
      "memory usage: 2.8 MB\n",
      "info of X_continous:: None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18372 entries, 0 to 18692\n",
      "Data columns (total 1 columns):\n",
      "category    18372 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 287.1 KB\n",
      "info of X_discrete:: None\n",
      "y:: Counter({1: 16701, 0: 1671})\n"
     ]
    }
   ],
   "source": [
    "# 将连续值和离散值以及y分开\n",
    "continuous_features = ['bys_cn', 'hindex_cn', 'a_paper', 'b_paper', 'c_paper', 'papernum2017', 'papernum2016', 'papernum2015', 'papernum2014', 'papernum2013', 'num_journal', 'num_conference',  'degree', 'pagerank', 'degree_centrality', 'diff_year', 'coauthors_top10000', 'coauthors_top20000', 'coauthors_top30000']\n",
    "discrete_features = ['category']\n",
    "X_continous = data[continuous_features]\n",
    "X_discrete = data[discrete_features]\n",
    "y = data['label']\n",
    "print(\"info of X_continous::\", X_continous.info())\n",
    "print(\"info of X_discrete::\", X_discrete.info())\n",
    "print(\"y::\", Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "shape of X_all:: (18372, 22)\n"
     ]
    }
   ],
   "source": [
    "# 对连续值进行归一化处理，对离散值进行one-hot编码\n",
    "# 暂时先不进行归一化处理，因为后面要寻找大方差的特征等\n",
    "# ss = StandardScaler()\n",
    "# X_continous = ss.fit_transform(X_continous)\n",
    "# print(\"type of X_continous::\", type(X_continous))\n",
    "\n",
    "X_discrete_oneHot = OneHotEncoder(sparse=False).fit_transform(X_discrete)\n",
    "print(X_discrete_oneHot)\n",
    "\n",
    "X_all = np.hstack((X_continous, X_discrete_oneHot))\n",
    "print(\"shape of X_all::\", X_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、Filter方法\n",
    "过滤法，按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。\n",
    "\n",
    "包括方差分析、相关系数法、卡方检验、F检验和互信息法。\n",
    "\n",
    "#### （1）方差分析\n",
    "方差较大的特征说明其取值发散，使用方差法，要先计算各个特征的方差，然后根据阈值，选择方差大于阈值的特征。\n",
    "#### （2）相关系数法\n",
    "皮尔逊系数只能衡量线性相关性，先要计算各个特征对目标值的相关系数以及相关系数的P值\n",
    "#### （3）卡方检验\n",
    "卡方检验只能用用于二分类。\n",
    "#### （4）F检验\n",
    "F检验和卡方检验都是检验的方法，f_classif用于分类模型，f_regression用于回归模型。\n",
    "#### （5）互信息法\n",
    "互信息稀疏反映相关性，互信息越大，说明越相关。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.00879970e+05 2.53632050e+01 2.53916840e+01 2.21470374e+01\n",
      " 7.53296860e+01 3.22170223e+01 3.18429028e+01 3.05619039e+01\n",
      " 2.77860064e+01 2.49705935e+01 2.84932472e+03 6.11521208e+02\n",
      " 1.07285265e+04 2.15172126e+02 8.16238752e+01 5.12690800e+01\n",
      " 2.40560804e+00 5.00732140e+00 7.80610567e+00 2.44977625e-01\n",
      " 1.84609727e-01 2.19926867e-01]\n",
      "[[ 41.   4.   0. ...   1.   3.   3.]\n",
      " [232.   8.   0. ...   1.   4.   4.]\n",
      " [103.   7.   0. ...   2.   4.   6.]\n",
      " ...\n",
      " [ 49.   2.   0. ...   0.   0.   0.]\n",
      " [  2.   2.   0. ...   1.   1.   2.]\n",
      " [ 21.   4.   0. ...   1.   2.   2.]]\n",
      "shape of X_new:: (18372, 19)\n"
     ]
    }
   ],
   "source": [
    "# 方差分析\n",
    "vt = VarianceThreshold(threshold=2)\n",
    "X_new = vt.fit_transform(X_all, y)\n",
    "print(vt.variances_)\n",
    "print(X_new)\n",
    "print(\"shape of X_new::\", X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      bys_cn  hindex_cn   a_paper   b_paper   c_paper  \\\n",
      "bys_cn              1.000000   0.644273  0.087185  0.120401  0.133408   \n",
      "hindex_cn           0.644273   1.000000  0.133651  0.181690  0.201967   \n",
      "a_paper             0.087185   0.133651  1.000000  0.742962  0.609541   \n",
      "b_paper             0.120401   0.181690  0.742962  1.000000  0.726083   \n",
      "c_paper             0.133408   0.201967  0.609541  0.726083  1.000000   \n",
      "papernum2017        0.232951   0.374031  0.524128  0.557366  0.603177   \n",
      "papernum2016        0.258163   0.409731  0.508840  0.559757  0.612475   \n",
      "papernum2015        0.275359   0.436976  0.500560  0.560156  0.616260   \n",
      "papernum2014        0.291261   0.466954  0.469717  0.548254  0.618209   \n",
      "papernum2013        0.316917   0.497253  0.453531  0.527905  0.592297   \n",
      "num_journal         0.462671   0.717891  0.274124  0.344442  0.383720   \n",
      "num_conference      0.224820   0.355659  0.681037  0.783751  0.865838   \n",
      "degree              0.358866   0.563126  0.444302  0.516786  0.574057   \n",
      "pagerank            0.216472   0.353981  0.502863  0.563897  0.624433   \n",
      "degree_centrality   0.359141   0.563702  0.443752  0.516250  0.573517   \n",
      "diff_year           0.249578   0.564935  0.131301  0.185543  0.204554   \n",
      "coauthors_top10000  0.135744   0.305586  0.191849  0.242325  0.299106   \n",
      "coauthors_top20000  0.164491   0.377725  0.176592  0.235953  0.295436   \n",
      "coauthors_top30000  0.179282   0.416392  0.160800  0.223263  0.279398   \n",
      "category1           0.033409   0.065436  0.100693  0.121859  0.121530   \n",
      "category2          -0.014607  -0.026702 -0.034133 -0.039013 -0.021251   \n",
      "category3          -0.021878  -0.044598 -0.075000 -0.092869 -0.108794   \n",
      "label               0.050256   0.147410  0.043664  0.059316  0.069538   \n",
      "\n",
      "                    papernum2017  papernum2016  papernum2015  papernum2014  \\\n",
      "bys_cn                  0.232951      0.258163      0.275359      0.291261   \n",
      "hindex_cn               0.374031      0.409731      0.436976      0.466954   \n",
      "a_paper                 0.524128      0.508840      0.500560      0.469717   \n",
      "b_paper                 0.557366      0.559757      0.560156      0.548254   \n",
      "c_paper                 0.603177      0.612475      0.616260      0.618209   \n",
      "papernum2017            1.000000      0.862078      0.814147      0.766949   \n",
      "papernum2016            0.862078      1.000000      0.855450      0.806506   \n",
      "papernum2015            0.814147      0.855450      1.000000      0.847200   \n",
      "papernum2014            0.766949      0.806506      0.847200      1.000000   \n",
      "papernum2013            0.719346      0.759730      0.799122      0.839047   \n",
      "num_journal             0.626153      0.666098      0.702876      0.730145   \n",
      "num_conference          0.683199      0.701475      0.709133      0.716288   \n",
      "degree                  0.666377      0.692656      0.699308      0.703170   \n",
      "pagerank                0.618338      0.631809      0.621216      0.612215   \n",
      "degree_centrality       0.666069      0.692492      0.698892      0.703027   \n",
      "diff_year               0.308215      0.326697      0.342919      0.361502   \n",
      "coauthors_top10000      0.319573      0.330026      0.322701      0.321246   \n",
      "coauthors_top20000      0.346728      0.361989      0.356578      0.363601   \n",
      "coauthors_top30000      0.355835      0.372388      0.370207      0.382078   \n",
      "category1               0.038081      0.036902      0.032331      0.022390   \n",
      "category2              -0.004594     -0.002768     -0.003961      0.003720   \n",
      "category3              -0.035983     -0.036412     -0.030493     -0.027040   \n",
      "label                   0.116434      0.122809      0.124599      0.124194   \n",
      "\n",
      "                    papernum2013  ...  pagerank  degree_centrality  diff_year  \\\n",
      "bys_cn                  0.316917  ...  0.216472           0.359141   0.249578   \n",
      "hindex_cn               0.497253  ...  0.353981           0.563702   0.564935   \n",
      "a_paper                 0.453531  ...  0.502863           0.443752   0.131301   \n",
      "b_paper                 0.527905  ...  0.563897           0.516250   0.185543   \n",
      "c_paper                 0.592297  ...  0.624433           0.573517   0.204554   \n",
      "papernum2017            0.719346  ...  0.618338           0.666069   0.308215   \n",
      "papernum2016            0.759730  ...  0.631809           0.692492   0.326697   \n",
      "papernum2015            0.799122  ...  0.621216           0.698892   0.342919   \n",
      "papernum2014            0.839047  ...  0.612215           0.703027   0.361502   \n",
      "papernum2013            1.000000  ...  0.604914           0.709925   0.379863   \n",
      "num_journal             0.751850  ...  0.512290           0.730122   0.534950   \n",
      "num_conference          0.711175  ...  0.703895           0.708221   0.322115   \n",
      "degree                  0.710090  ...  0.937031           0.999485   0.434319   \n",
      "pagerank                0.604914  ...  1.000000           0.936491   0.318669   \n",
      "degree_centrality       0.709925  ...  0.936491           1.000000   0.435641   \n",
      "diff_year               0.379863  ...  0.318669           0.435641   1.000000   \n",
      "coauthors_top10000      0.331717  ...  0.339194           0.400904   0.274195   \n",
      "coauthors_top20000      0.375090  ...  0.348095           0.438721   0.343076   \n",
      "coauthors_top30000      0.396989  ...  0.343368           0.453871   0.385774   \n",
      "category1               0.031794  ...  0.086739           0.079589  -0.031121   \n",
      "category2              -0.007084  ... -0.005975          -0.013511   0.011045   \n",
      "category3              -0.027065  ... -0.086071          -0.071620   0.022726   \n",
      "label                   0.126110  ...  0.099205           0.130641   0.258360   \n",
      "\n",
      "                    coauthors_top10000  coauthors_top20000  \\\n",
      "bys_cn                        0.135744            0.164491   \n",
      "hindex_cn                     0.305586            0.377725   \n",
      "a_paper                       0.191849            0.176592   \n",
      "b_paper                       0.242325            0.235953   \n",
      "c_paper                       0.299106            0.295436   \n",
      "papernum2017                  0.319573            0.346728   \n",
      "papernum2016                  0.330026            0.361989   \n",
      "papernum2015                  0.322701            0.356578   \n",
      "papernum2014                  0.321246            0.363601   \n",
      "papernum2013                  0.331717            0.375090   \n",
      "num_journal                   0.321304            0.384312   \n",
      "num_conference                0.367974            0.382523   \n",
      "degree                        0.400957            0.438633   \n",
      "pagerank                      0.339194            0.348095   \n",
      "degree_centrality             0.400904            0.438721   \n",
      "diff_year                     0.274195            0.343076   \n",
      "coauthors_top10000            1.000000            0.848676   \n",
      "coauthors_top20000            0.848676            1.000000   \n",
      "coauthors_top30000            0.773444            0.923758   \n",
      "category1                     0.173294            0.161626   \n",
      "category2                    -0.020831           -0.014651   \n",
      "category3                    -0.163812           -0.157160   \n",
      "label                         0.100816            0.128305   \n",
      "\n",
      "                    coauthors_top30000  category1  category2  category3  \\\n",
      "bys_cn                        0.179282   0.033409  -0.014607  -0.021878   \n",
      "hindex_cn                     0.416392   0.065436  -0.026702  -0.044598   \n",
      "a_paper                       0.160800   0.100693  -0.034133  -0.075000   \n",
      "b_paper                       0.223263   0.121859  -0.039013  -0.092869   \n",
      "c_paper                       0.279398   0.121530  -0.021251  -0.108794   \n",
      "papernum2017                  0.355835   0.038081  -0.004594  -0.035983   \n",
      "papernum2016                  0.372388   0.036902  -0.002768  -0.036412   \n",
      "papernum2015                  0.370207   0.032331  -0.003961  -0.030493   \n",
      "papernum2014                  0.382078   0.022390   0.003720  -0.027040   \n",
      "papernum2013                  0.396989   0.031794  -0.007084  -0.027065   \n",
      "num_journal                   0.424573   0.022996  -0.001674  -0.022736   \n",
      "num_conference                0.375854   0.132548  -0.013953  -0.127110   \n",
      "degree                        0.453580   0.080336  -0.013439  -0.072476   \n",
      "pagerank                      0.343368   0.086739  -0.005975  -0.086071   \n",
      "degree_centrality             0.453871   0.079589  -0.013511  -0.071620   \n",
      "diff_year                     0.385774  -0.031121   0.011045   0.022726   \n",
      "coauthors_top10000            0.773444   0.173294  -0.020831  -0.163812   \n",
      "coauthors_top20000            0.923758   0.161626  -0.014651  -0.157160   \n",
      "coauthors_top30000            1.000000   0.129493  -0.008977  -0.128444   \n",
      "category1                     0.129493   1.000000  -0.492942  -0.603785   \n",
      "category2                    -0.008977  -0.492942   1.000000  -0.395936   \n",
      "category3                    -0.128444  -0.603785  -0.395936   1.000000   \n",
      "label                         0.142068  -0.051024   0.023273   0.032481   \n",
      "\n",
      "                       label  \n",
      "bys_cn              0.050256  \n",
      "hindex_cn           0.147410  \n",
      "a_paper             0.043664  \n",
      "b_paper             0.059316  \n",
      "c_paper             0.069538  \n",
      "papernum2017        0.116434  \n",
      "papernum2016        0.122809  \n",
      "papernum2015        0.124599  \n",
      "papernum2014        0.124194  \n",
      "papernum2013        0.126110  \n",
      "num_journal         0.137592  \n",
      "num_conference      0.096930  \n",
      "degree              0.130065  \n",
      "pagerank            0.099205  \n",
      "degree_centrality   0.130641  \n",
      "diff_year           0.258360  \n",
      "coauthors_top10000  0.100816  \n",
      "coauthors_top20000  0.128305  \n",
      "coauthors_top30000  0.142068  \n",
      "category1          -0.051024  \n",
      "category2           0.023273  \n",
      "category3           0.032481  \n",
      "label               1.000000  \n",
      "\n",
      "[23 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# 相关系数法\n",
    "columns = ['bys_cn', 'hindex_cn', 'a_paper', 'b_paper', 'c_paper', 'papernum2017', 'papernum2016', 'papernum2015', 'papernum2014', 'papernum2013', 'num_journal', 'num_conference',  'degree', 'pagerank', 'degree_centrality', 'diff_year', 'coauthors_top10000', 'coauthors_top20000', 'coauthors_top30000', 'category1', 'category2', 'category3']\n",
    "X_all_df = pd.DataFrame(X_all, columns=columns)\n",
    "# print(\"info of X_all_df::\", X_all_df.info())\n",
    "y_df = pd.DataFrame(y, columns = ['label'])\n",
    "# print(\"info of y_df::\", y_df.info())\n",
    "X_y_all_df = pd.concat([X_all_df, y_df], axis=1)\n",
    "# print(\"info of X_y_all_df::\", X_y_all_df.info())\n",
    "print(X_y_all_df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 41.   4.   0. ...   4.   8.   3.]\n",
      " [232.   8.   0. ...   4.  16.   4.]\n",
      " [103.   7.   4. ...   6.  17.   6.]\n",
      " ...\n",
      " [ 49.   2.   0. ...   0.   0.   0.]\n",
      " [  2.   2.   0. ...   0.   0.   2.]\n",
      " [ 21.   4.   0. ...   3.  10.   2.]]\n",
      "[2.89499631e+05 6.27809793e+03 1.63989737e+03 2.07044726e+03\n",
      " 4.55888006e+03 5.47715196e+03 5.60851137e+03 5.55383244e+03\n",
      " 5.39025576e+03 5.16561683e+03 6.24744338e+04 1.91444981e+04\n",
      " 1.15097539e+05 1.36631954e+04 1.03057973e+04 1.83392585e+04\n",
      " 7.77844366e+02 1.48823845e+03 2.26304244e+03 4.62240511e+02\n",
      " 1.48370439e+01 4.54277219e+02]\n",
      "[0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 3.54143396e-171 0.00000000e+000 0.00000000e+000 1.56429966e-102\n",
      " 1.17210465e-004 8.45832075e-101]\n"
     ]
    }
   ],
   "source": [
    "# 卡方检验\n",
    "k_chi = SelectKBest(chi2, k=15)\n",
    "X_chi = k_chi.fit_transform(X_all, data['label'])\n",
    "print(X_chi)\n",
    "print(k_chi.scores_)\n",
    "print(k_chi.pvalues_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4. 3. 3. ... 3. 0. 1.]\n",
      " [8. 2. 2. ... 4. 0. 1.]\n",
      " [7. 4. 4. ... 6. 0. 1.]\n",
      " ...\n",
      " [2. 0. 0. ... 0. 1. 0.]\n",
      " [2. 0. 0. ... 2. 1. 0.]\n",
      " [4. 0. 0. ... 2. 1. 0.]]\n",
      "[ 134.84869814 1629.49073283   60.17944086  110.59771289  159.88717488\n",
      "  553.57810775  601.44707216  613.1734877   636.56291361  660.83315752\n",
      "  872.58167833  358.35741816  849.04675701  534.16085324  869.44003403\n",
      " 7024.53190704  462.316657    772.59561546 1059.26463256  846.95410797\n",
      "   19.65197876  700.22374718]\n",
      "[4.57473344e-031 0.00000000e+000 9.11046861e-015 8.58106003e-026\n",
      " 1.69979600e-036 1.26968235e-120 1.01976728e-130 3.46406053e-133\n",
      " 4.16754562e-138 3.32352335e-143 2.11323083e-187 3.63684764e-079\n",
      " 1.63075689e-182 1.60826642e-116 9.48440744e-187 0.00000000e+000\n",
      " 2.66441851e-101 1.35321364e-166 5.91695246e-226 4.43876376e-182\n",
      " 9.34453381e-006 1.82601260e-151]\n"
     ]
    }
   ],
   "source": [
    "# F检验\n",
    "k_f = SelectKBest(f_classif, k=15)\n",
    "X_f = k_f.fit_transform(X_all, data['label'])\n",
    "print(X_f)\n",
    "print(k_f.scores_)\n",
    "print(k_f.pvalues_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 41.   4.   3. ...   8.   3.   3.]\n",
      " [232.   8.   2. ...  16.   4.   4.]\n",
      " [103.   7.   4. ...  17.   4.   6.]\n",
      " ...\n",
      " [ 49.   2.   0. ...   0.   0.   0.]\n",
      " [  2.   2.   0. ...   0.   1.   2.]\n",
      " [ 21.   4.   0. ...  10.   2.   2.]]\n",
      "[0.10540583 0.11665173 0.01237054 0.02177251 0.03069601 0.07133708\n",
      " 0.07090184 0.0726609  0.07564243 0.07192766 0.16035275 0.07071606\n",
      " 0.14977129 0.13504637 0.14375653 0.17178321 0.02072033 0.03250934\n",
      " 0.04711023 0.02357239 0.         0.02039823]\n"
     ]
    }
   ],
   "source": [
    "# 互信息法\n",
    "k_info = SelectKBest(mutual_info_classif, k=15)\n",
    "X_info = k_info.fit_transform(X_all, data['label'])\n",
    "print(X_info)\n",
    "print(k_info.scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、Wrapper方法\n",
    "包装法，根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。包裹式特征选择直接把最终将要使用的模型的性能作为特征子集的评价标准，也就是说，包裹式特征选择的目的就是为给定的模型选择最有利于其性能的特征子集。\n",
    "\n",
    "从模型的性能来看，包裹式特征选择比过滤式特征选择更好，但需要多次训练模型，因此计算开销较大。\n",
    "\n",
    "包括递归特征消除法等。\n",
    "\n",
    "#### （1）递归特征消除法\n",
    "递归消除特征法使用一个基模型来进行多轮训练，每轮训练后，消除若干权值系数的特征，再基于新的特征集进行下一轮训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4. 0. 0. ... 0. 0. 1.]\n",
      " [8. 0. 0. ... 0. 0. 1.]\n",
      " [7. 0. 4. ... 0. 0. 1.]\n",
      " ...\n",
      " [2. 0. 0. ... 1. 0. 0.]\n",
      " [2. 0. 0. ... 1. 0. 0.]\n",
      " [4. 0. 0. ... 1. 0. 0.]]\n",
      "15\n",
      "[False  True False  True  True  True False  True  True  True False False\n",
      "  True  True False  True False  True  True  True  True  True]\n",
      "[8 1 4 1 1 1 5 1 1 1 3 2 1 1 6 1 7 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# RFE\n",
    "model_lg = RFE(estimator=LogisticRegression(), n_features_to_select=15)\n",
    "X_lg = model_lg.fit_transform(X_all, data['label'])\n",
    "print(X_lg)\n",
    "print(model_lg.n_features_)\n",
    "print(model_lg.support_)\n",
    "print(model_lg.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4. 0. 0. ... 0. 0. 1.]\n",
      " [8. 0. 0. ... 0. 0. 1.]\n",
      " [7. 0. 4. ... 0. 0. 1.]\n",
      " ...\n",
      " [2. 0. 0. ... 1. 0. 0.]\n",
      " [2. 0. 0. ... 1. 0. 0.]\n",
      " [4. 0. 0. ... 1. 0. 0.]]\n",
      "15\n",
      "[False  True False  True  True  True False  True  True  True False False\n",
      "  True  True False  True False  True  True  True  True  True]\n",
      "[8 1 4 1 1 1 5 1 1 1 3 2 1 1 6 1 7 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# RFECV\n",
    "model_lg_cv = RFECV(estimator=LogisticRegression(), step=1, cv=StratifiedKFold(n_splits=3), scoring=\"accuracy\")\n",
    "X_lg_cv = model_lg_cv.fit_transform(X_all, data['label'])\n",
    "print(X_lg_cv)\n",
    "print(model_lg_cv.n_features_)\n",
    "print(model_lg_cv.support_)\n",
    "print(model_lg_cv.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5、Embedded方法\n",
    "集成法，先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是是通过训练来确定特征的优劣。\n",
    "\n",
    "包括基于树模型的特征选择法、正则化方法等。\n",
    "\n",
    "#### （1）基于树模型的特征选择法\n",
    "树模型中GBDT也可用来作为基模型进行特征选择。\n",
    "\n",
    "#### （2）基于L1的特征选择法\n",
    "使用L1范数作为惩罚项的线性模型会得到稀疏解，可以起到特征选择的作用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48.  8.  1.]\n",
      " [45. 16.  1.]\n",
      " [73. 17.  1.]\n",
      " ...\n",
      " [ 2.  0.  0.]\n",
      " [ 5.  0.  0.]\n",
      " [34. 10.  0.]]\n",
      "shape of X_gdbc:: (18372, 3)\n"
     ]
    }
   ],
   "source": [
    "# 基于树模型的特征选择法\n",
    "model_gdbc= SelectFromModel(GradientBoostingClassifier())\n",
    "X_gdbc = model_gdbc.fit_transform(X_all, data['label'])\n",
    "print(X_gdbc)\n",
    "print(\"shape of X_gdbc::\", X_gdbc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 41.   4.   3. ...   3.   0.   1.]\n",
      " [232.   8.   2. ...   4.   0.   1.]\n",
      " [103.   7.   4. ...   6.   0.   1.]\n",
      " ...\n",
      " [ 49.   2.   0. ...   0.   1.   0.]\n",
      " [  2.   2.   0. ...   2.   1.   0.]\n",
      " [ 21.   4.   0. ...   2.   1.   0.]]\n",
      "shape of X_lsvc:: (18372, 14)\n"
     ]
    }
   ],
   "source": [
    "# L1正则化\n",
    "model_lsvc = SelectFromModel(LinearSVC(C=0.01, penalty=\"l1\", dual=False))\n",
    "X_lsvc = model_lsvc.fit_transform(X_all, data['label']) \n",
    "print(X_lsvc)\n",
    "print(\"shape of X_lsvc::\", X_lsvc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
